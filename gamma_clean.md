# ClassMate - Technical Architecture Portfolio
## Complete System Visualization for Gamma

---

## ğŸ“‹ Slide 1: Title

**ClassMate**
**AI-Powered CSAT English Learning Platform**

í•µì‹¬ ê¸°ìˆ : OpenAI Function Calling + ReAct Pattern + Neo4j GraphRAG

100% Exam Parsing Accuracy | Intelligent Routing | Dynamic Function Selection

---

## ğŸ“š Slide 2: ìš©ì–´ ì •ì˜

### 1. CSAT (ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜)

**CSAT = College Scholastic Ability Test**
- í•œêµ­ì˜ ëŒ€í•™ ì…í•™ ì‹œí—˜ (ìˆ˜ëŠ¥)
- ì˜ì–´ ì˜ì—­: ë“£ê¸° 17ë¬¸í•­ + ë…í•´ 28ë¬¸í•­ = ì´ 45ë¬¸í•­
- ë‚œì´ë„: CEFR B1~C1 ìˆ˜ì¤€
- ClassMateëŠ” CSAT ì˜ì–´ ì‹œí—˜ì§€ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ë¶„ë¥˜

### 2. JWT (JSON Web Token) ì¸ì¦

**Stateless Token-Based Authentication**

```
Client                 Server                   Neo4j
  |                      |                       |
  |--POST /api/auth/---->|                       |
  |  login               |                       |
  |  {username,password} |--Cypher Query-------->|
  |                      |<--User Data-----------|
  |                      |                       |
  |<--JWT Token----------|                       |
  |  (signed payload)    |                       |
  |                      |                       |
  |--GET /api/chat------>|                       |
  |  Authorization:      |                       |
  |  Bearer <JWT>        |                       |
  |                      |--Verify JWT---------->|
  |                      |  (decode + validate)  |
  |                      |                       |
  |<--Protected Data-----|                       |
```

**JWT Payload ì˜ˆì‹œ**:
```json
{
  "user_id": "S-01",
  "role": "student",
  "name": "ê¹€ë¯¼ì¤€",
  "cefr_level": "B1",
  "exp": 1735689600
}
```

**ì¥ì **:
- Stateless: ì„œë²„ì— ì„¸ì…˜ ì €ì¥ ë¶ˆí•„ìš”
- Scalable: ë¡œë“œ ë°¸ëŸ°ì„œì™€ í˜¸í™˜
- Secure: HMAC ì„œëª…ìœ¼ë¡œ ìœ„ë³€ì¡° ë°©ì§€

### 3. ReAct Pattern

**ReAct = Reasoning + Acting**

ë³µì¡í•œ ì‘ì—…ì„ **ì‚¬ê³ (Thought) â†’ í–‰ë™(Action) â†’ ê´€ì°°(Observation)** ë°˜ë³µìœ¼ë¡œ í•´ê²°

**ì˜ˆì‹œ**: "ë…í•´ ì•½í•œ í•™ìƒë“¤ ì°¾ì•„ì„œ ë§ì¶¤ ê³„íš ì„¸ì›Œì¤˜"

```
Step 1:
  Thought: "ë¨¼ì € ë…í•´ 70ì  ë¯¸ë§Œ í•™ìƒì„ ì°¾ì•„ì•¼ê² ë‹¤"
  Action: search_students_by_score(area="ë…í•´", threshold=70)
  Observation: "5ëª…ì˜ í•™ìƒ ë°œê²¬ (ê¹€ë¯¼ì¤€, ì´ì„œìœ¤, ...)"

Step 2:
  Thought: "ê° í•™ìƒì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•´ì•¼ ë§ì¶¤ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ìˆë‹¤"
  Action: get_student_details(student_id="S-01")
  Observation: "ê¹€ë¯¼ì¤€ - CEFR B1, ì–´íœ˜ ì•½í•¨, ì¶œì„ë¥  90%"

Step 3:
  Thought: "í•™ìƒë³„ ì•½ì ì„ ê³ ë ¤í•œ 4ì£¼ ê³„íšì„ ìƒì„±í•˜ì"
  Action: recommend_improvement_areas(student_id="S-01", priority="urgent")
  Observation: "4ì£¼ ê³„íš ìƒì„± ì™„ë£Œ"

Final Answer: "5ëª…ì˜ í•™ìƒ ë§ì¶¤ ê³„íš ì œì‹œ"
```

### 4. Function Calling

**GPTê°€ ìƒí™©ì— ë§ê²Œ í•¨ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ì—¬ ì‹¤í–‰**

```python
functions = [
    {
        "name": "get_student_context",
        "description": "í•™ìƒì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ (Neo4j)",
        "parameters": {"student_id": "S-01"}
    },
    {
        "name": "recommend_problems",
        "description": "ì•½ì  ê¸°ë°˜ ë¬¸ì œ ì¶”ì²œ (GraphRAG)",
        "parameters": {"student_id": "S-01", "area": "ë…í•´"}
    },
    {
        "name": "generate_problem",
        "description": "AI ë¬¸ì œ ìƒì„± (o4-mini)",
        "parameters": {"area": "ë“£ê¸°", "difficulty": "B1"}
    }
]

# GPTê°€ ìë™ìœ¼ë¡œ ì ì ˆí•œ í•¨ìˆ˜ ì„ íƒ
response = openai.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[{"role": "user", "content": "ë…í•´ ì•½í•œë° ë¬¸ì œ ë‚´ì¤˜"}],
    tools=functions,
    tool_choice="auto"  # ìë™ ì„ íƒ!
)

# GPT ì„ íƒ: recommend_problems(student_id="S-01", area="ë…í•´")
```

---

## ğŸ§  Slide 3: Intelligent Routing System

### Query Complexity Analysis â†’ Model Selection

```mermaid
graph TD
    U[User Query: ë…í•´ ì•½ì  ë¶„ì„í•˜ê³  4ì£¼ ê³„íš ì„¸ì›Œì¤˜] -->|1. Routing| R[Router gpt-4o-mini]

    R -->|Analyze Complexity| D{Decision}

    D -->|Simple Task| I[Intelligence Mode<br/>gpt-4.1-mini<br/>ë¹ ë¥¸ ì •ë³´ ì¡°íšŒ]
    D -->|Complex Task| RE[Reasoning Mode<br/>o4-mini<br/>ì‹¬ì¸µ ì¶”ë¡ ]

    I --> I1[ë‹¨ìˆœ ì •ë³´ ì¡°íšŒ<br/>DB ì¿¼ë¦¬ë§Œ í•„ìš”<br/>ì˜ˆ: ì„±ì  í™•ì¸, ì¶œì„ë¥ ]

    RE --> RE1[ë³µì¡í•œ ë¶„ì„<br/>ë‹¤ë‹¨ê³„ ì¶”ë¡  í•„ìš”<br/>ì˜ˆ: í•™ìŠµ ê³„íš ìˆ˜ë¦½]

    RE1 -->|Quality Check| QC{Response<br/>Quality OK?}

    QC -->|Good| DONE[Return Response]
    QC -->|Poor| O3[Fallback to o3<br/>ìµœê³ ê¸‰ ì¶”ë¡ ]

    O3 --> DONE

    style R fill:#f9ca24,stroke:#333,stroke-width:2px
    style I fill:#4ecdc4,stroke:#333,stroke-width:2px
    style RE fill:#ff6b6b,stroke:#333,stroke-width:2px
    style O3 fill:#a29bfe,stroke:#333,stroke-width:2px
```

### Routing Decision Criteria

| Query Type | Complexity | Routed To | Reason |
|------------|------------|-----------|--------|
| "ì„±ì  ì•Œë ¤ì¤˜" | Simple | gpt-4.1-mini | DB ì¡°íšŒë§Œ í•„ìš” |
| "ë¬¸ì œ ë‚´ì¤˜" | Simple | gpt-4.1-mini | Function call 1íšŒ |
| "ì•½ì  ë¶„ì„í•˜ê³  ê³„íš ì„¸ì›Œì¤˜" | Complex | o4-mini | ë‹¤ë‹¨ê³„ ì¶”ë¡  í•„ìš” |
| "ë…í•´ì™€ ë¬¸ë²• ì¤‘ ë­˜ ë¨¼ì €?" | Complex | o4-mini | ë¹„êµ ë¶„ì„ + ì „ëµ ìˆ˜ë¦½ |

### Routing Code

```python
def _route_query(message: str) -> str:
    """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„ â†’ intelligence vs reasoning"""

    routing_prompt = f'''Analyze this question:

**intelligence** (gpt-4.1-mini) - Fast:
- Simple info lookup (ì„±ì , ì¶œì„ë¥ )
- Single function call (ë¬¸ì œ ë‚´ì¤˜)
- Greetings (ì•ˆë…•?)

**reasoning** (o4-mini) - Deep thinking:
- Multi-step analysis (ì•½ì  ë¶„ì„í•˜ê³  ê³„íš ì„¸ì›Œì¤˜)
- Comparative reasoning (A vs B ë¹„êµ)
- Strategic planning (í•™ìŠµ ì „ëµ ìˆ˜ë¦½)

Question: "{message}"

Respond: "intelligence" or "reasoning"'''

    response = openai.chat.completions.create(
        model="gpt-4o-mini",  # Fast router
        messages=[{"role": "user", "content": routing_prompt}],
        temperature=0
    )

    return response.choices[0].message.content.strip()
```

---

## ğŸ”„ Slide 4: ReAct Pattern - Multi-Step Reasoning

### ReAct Workflow

```mermaid
sequenceDiagram
    participant U as User
    participant R as ReAct Engine<br/>(o4-mini)
    participant F as Functions
    participant N as Neo4j DB

    U->>R: "ë…í•´ ì•½í•œ í•™ìƒ ì°¾ì•„ì„œ ê³„íš ì„¸ì›Œì¤˜"

    rect rgb(200, 220, 250)
        Note over R: Step 1: Reasoning
        R->>R: ğŸ’­ Thought: "ë¨¼ì € ë…í•´ ì ìˆ˜ ë‚®ì€ í•™ìƒ ê²€ìƒ‰"
        R->>F: ğŸ”§ Action: search_students_by_score(area="ë…í•´", threshold=70)
        F->>N: Cypher Query
        N-->>F: [5 students found]
        F-->>R: ğŸ“Š Observation: "ê¹€ë¯¼ì¤€, ì´ì„œìœ¤ ì™¸ 3ëª…"
    end

    rect rgb(220, 240, 200)
        Note over R: Step 2: Reasoning
        R->>R: ğŸ’­ Thought: "ì²« ë²ˆì§¸ í•™ìƒ ìƒì„¸ ì •ë³´ í•„ìš”"
        R->>F: ğŸ”§ Action: get_student_details(student_id="S-01")
        F->>N: GraphRAG Context
        N-->>F: [Student data + weak areas]
        F-->>R: ğŸ“Š Observation: "B1 ë ˆë²¨, ì–´íœ˜/ë¬¸ë²• ì•½í•¨"
    end

    rect rgb(250, 230, 200)
        Note over R: Step 3: Reasoning
        R->>R: ğŸ’­ Thought: "ë§ì¶¤ í•™ìŠµ ê³„íš ìƒì„±"
        R->>F: ğŸ”§ Action: recommend_improvement_areas(priority="urgent")
        F->>R: ğŸ“Š Observation: "4ì£¼ ê³„íš ì™„ë£Œ"
    end

    R->>R: âœ… Final Answer: "5ëª…ì˜ í•™ìƒë³„ ë§ì¶¤ ê³„íš ì œì‹œ"
    R-->>U: [Detailed Response]
```

### ReAct vs ì¼ë°˜ ëª¨ë“œ ë¹„êµ

| íŠ¹ì§• | ì¼ë°˜ ëª¨ë“œ (Single-Step) | ReAct ëª¨ë“œ (Multi-Step) |
|------|------------------------|-------------------------|
| ì§ˆë¬¸ ì˜ˆì‹œ | "ì„±ì  ì•Œë ¤ì¤˜" | "ì•½ì  ë¶„ì„í•˜ê³  ê³„íš ì„¸ì›Œì¤˜" |
| Function Call | 1íšŒ | 3-5íšŒ (iterative) |
| ì‚¬ê³  ê³¼ì • | ì—†ìŒ | Thought â†’ Action â†’ Observation |
| ìµœëŒ€ Step | 1 | 5 (configurable) |
| ëª¨ë¸ | gpt-4.1-mini | o4-mini (reasoning) |
| ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ | ë‹¨ìˆœ ì¡°íšŒ | ë³µì¡í•œ ë¶„ì„, ê³„íš ìˆ˜ë¦½ |

### ReAct í™œì„±í™” ì¡°ê±´

```python
def _needs_react(message: str) -> bool:
    """ReAct ëª¨ë“œ í•„ìš” ì—¬ë¶€ íŒë‹¨"""

    # íŒ¨í„´ 1: ì—°ê²°ì–´ (í•˜ê³ , ì°¾ì•„ì„œ)
    multi_task_keywords = ['í•˜ê³ ', 'ì°¾ì•„ì„œ', 'í™•ì¸í•˜ê³ ', 'ë¶„ì„í•˜ê³ ']
    for keyword in multi_task_keywords:
        if keyword in message:
            return True

    # íŒ¨í„´ 2: ìˆœì°¨ì  ì§€ì‹œ (ë¨¼ì € ... ê·¸ë‹¤ìŒ)
    if 'ë¨¼ì €' in message and 'ê·¸ë‹¤ìŒ' in message:
        return True

    # íŒ¨í„´ 3: ë™ì‚¬ 3ê°œ ì´ìƒ
    action_verbs = ['ì°¾', 'ë¶„ì„', 'ì¶”ì²œ', 'í™•ì¸', 'ë¹„êµ', 'ì„¤ëª…']
    verb_count = sum(1 for verb in action_verbs if verb in message)
    if verb_count >= 3:
        return True

    return False
```

---

## ğŸ”§ Slide 5: Function Calling Architecture

### 3-Role Agent System

```mermaid
graph TB
    subgraph "Student Agent (8 Functions)"
        S1[get_student_context<br/>í•™ìƒ ì •ë³´ ì¡°íšŒ]
        S2[recommend_problems<br/>DB ë¬¸ì œ ì¶”ì²œ]
        S3[generate_problem<br/>AI ë¬¸ì œ ìƒì„±]
        S4[evaluate_writing<br/>ì„œìˆ í˜• í‰ê°€]
        S5[lookup_word<br/>ë‹¨ì–´ ê²€ìƒ‰ API]
        S6[fetch_news<br/>ë‰´ìŠ¤ API]
        S7[analyze_text_difficulty<br/>ë‚œì´ë„ ë¶„ì„]
        S8[check_grammar<br/>ë¬¸ë²• ê²€ì‚¬ API]
    end

    subgraph "Teacher Agent (10 Functions)"
        T1[get_my_class_students<br/>ë‹´ë‹¹ ë°˜ ì¡°íšŒ]
        T2[search_students_by_score<br/>ì ìˆ˜ ê¸°ì¤€ ê²€ìƒ‰]
        T3[search_students_by_behavior<br/>íƒœë„ ê¸°ì¤€ ê²€ìƒ‰]
        T4[get_student_details<br/>í•™ìƒ ìƒì„¸ ì •ë³´]
        T5[trigger_exam_upload_ui<br/>ì‹œí—˜ì§€ ì—…ë¡œë“œ UI]
        T6[trigger_daily_input_ui<br/>ê¸°ë¡ë¶€ UI]
        T7[lookup_word<br/>ë‹¨ì–´ ê²€ìƒ‰]
        T8[fetch_news<br/>ë‰´ìŠ¤ ê²€ìƒ‰]
        T9[analyze_text_difficulty<br/>ë‚œì´ë„ ë¶„ì„]
        T10[check_grammar<br/>ë¬¸ë²• ê²€ì‚¬]
    end

    subgraph "Parent Agent (10 Functions)"
        P1[get_child_info<br/>ìë…€ ì •ë³´ ì¡°íšŒ]
        P2[analyze_performance<br/>ì„±ì  ë¶„ì„]
        P3[get_study_advice<br/>í•™ìŠµ ì¡°ì–¸ ìƒì„±]
        P4[get_attendance_status<br/>ì¶œì„ í˜„í™©]
        P5[recommend_improvement_areas<br/>ê°œì„  ì˜ì—­ ì¶”ì²œ]
        P6[generate_problem<br/>ë¬¸ì œ ìƒì„±]
        P7[lookup_word<br/>ë‹¨ì–´ ê²€ìƒ‰]
        P8[fetch_news<br/>ë‰´ìŠ¤ ê²€ìƒ‰]
        P9[analyze_text_difficulty<br/>ë‚œì´ë„ ë¶„ì„]
        P10[search_youtube<br/>YouTube ê²€ìƒ‰]
    end

    style S3 fill:#ff6b6b,stroke:#333,stroke-width:2px
    style S4 fill:#ff6b6b,stroke:#333,stroke-width:2px
    style T5 fill:#f9ca24,stroke:#333,stroke-width:2px
    style T6 fill:#f9ca24,stroke:#333,stroke-width:2px
    style P3 fill:#6c5ce7,stroke:#333,stroke-width:2px
    style P5 fill:#6c5ce7,stroke:#333,stroke-width:2px
```

### Function Type Classification

| Function Type | Functions | Execution Target |
|---------------|-----------|------------------|
| **ğŸ“Š DATABASE QUERY** | get_student_context, recommend_problems, get_my_class_students | Neo4j Cypher |
| **ğŸ¤– AI GENERATION** | generate_problem (o4-mini), evaluate_writing (o4-mini), get_study_advice (gpt-4o) | OpenAI API |
| **ğŸŒ EXTERNAL API** | lookup_word (Free Dictionary), fetch_news (NewsAPI), check_grammar (LanguageTool) | 3rd Party APIs |
| **ğŸ–¥ï¸ UI TRIGGER** | trigger_exam_upload_ui, trigger_daily_input_ui | Frontend Panel |

---

## ğŸ¯ Slide 6: Complete Request Flow - Student Example

### "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜" â†’ AI Problem Generation

```mermaid
sequenceDiagram
    participant U as Student<br/>"ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"
    participant R as Router<br/>gpt-4o-mini
    participant A as Agent<br/>gpt-4.1-mini
    participant F1 as generate_problem<br/>Function
    participant O as o4-mini<br/>Reasoning Model
    participant T as TTS Service<br/>OpenAI TTS
    participant U2 as User

    U->>R: "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"

    R->>R: Analyze complexity
    R-->>A: Route to: intelligence (simple task)

    A->>A: Parse request<br/>area="ë“£ê¸°", difficulty=auto
    A->>F1: ğŸ”§ Call: generate_problem(area="ë“£ê¸°")

    F1->>O: Generate listening dialogue<br/>with [AUDIO] + [SPEAKERS] tags
    O->>O: ğŸ’­ Create realistic conversation<br/>2 speakers, natural flow
    O-->>F1: Dialogue + Question + Options

    F1->>F1: Post-process<br/>- Add [AUDIO]: tag<br/>- Generate [SPEAKERS] JSON

    F1->>T: Request TTS audio<br/>(dialogue + speakers metadata)
    T->>T: Generate multi-voice audio<br/>Samantha (F) + David (M)
    T-->>F1: Audio URL: /static/audio/abc123.mp3

    F1-->>A: [AUDIO_URL]: /static/audio/abc123.mp3<br/>[AUDIO]:<br/>[SPEAKERS]: {...}<br/>Woman: Hey...

    A-->>U2: ğŸ“ ë“£ê¸° ë¬¸ì œ ì¤€ë¹„í–ˆì–´!<br/><br/>[Audio Player]<br/>[English Dialogue]<br/>[Question + 5 Options]
```

### Function Calling Code Example

```python
# Student asks: "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"

# Step 1: Router analyzes
router_decision = _route_query("ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜", student_id)
# Returns: "intelligence" (simple task)

# Step 2: Primary model (gpt-4.1-mini) with function calling
response = openai.chat.completions.create(
    model="gpt-4.1-mini",
    messages=[
        {"role": "system", "content": student_system_prompt},
        {"role": "user", "content": "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"}
    ],
    tools=student_functions,  # 8 available functions
    tool_choice="auto"  # GPT decides which function to call
)

# GPT decides: generate_problem(student_id="S-01", area="ë“£ê¸°")
tool_call = response.choices[0].message.tool_calls[0]
function_name = tool_call.function.name  # "generate_problem"
arguments = json.loads(tool_call.function.arguments)
# {"student_id": "S-01", "area": "ë“£ê¸°", "difficulty": null}

# Step 3: Execute function
result = _generate_problem(**arguments)
# Uses o4-mini to create dialogue, then TTS to generate audio

# Step 4: Return to user
# result contains [AUDIO_URL], [AUDIO], [SPEAKERS], dialogue, question, options
```

---

## ğŸ”€ Slide 7: Dynamic Model Selection

### 4-Layer Model Strategy

```mermaid
graph TD
    Q[User Query] --> L1[Layer 1: Router<br/>gpt-4o-mini]

    L1 -->|Simple| L2A[Layer 2a: Intelligence<br/>gpt-4.1-mini]
    L1 -->|Complex| L2B[Layer 2b: Reasoning<br/>o4-mini]

    L2A --> FC1[Function Calling]
    L2B --> FC2[Function Calling + ReAct]

    FC1 --> L3A[Layer 3: Function Models]
    FC2 --> L3A

    L3A --> G1[generate_problem<br/>â†’ o4-mini]
    L3A --> G2[evaluate_writing<br/>â†’ o4-mini]
    L3A --> G3[get_study_advice<br/>â†’ gpt-4o]
    L3A --> G4[DB Query<br/>â†’ Neo4j]

    L2B --> QC{Quality Check}
    QC -->|Poor| L4[Layer 4: Fallback<br/>o3]
    QC -->|Good| DONE[Response]
    L4 --> DONE

    style L1 fill:#f9ca24,stroke:#333,stroke-width:3px
    style L2A fill:#4ecdc4,stroke:#333,stroke-width:2px
    style L2B fill:#ff6b6b,stroke:#333,stroke-width:2px
    style L4 fill:#a29bfe,stroke:#333,stroke-width:3px
```

### Model Usage Table

| Layer | Model | Purpose | Cost | Speed | Quality |
|-------|-------|---------|------|-------|---------|
| **1. Router** | gpt-4o-mini | Complexity analysis | $ | âš¡âš¡âš¡ | â­â­â­ |
| **2a. Intelligence** | gpt-4.1-mini | Simple queries + Function calling | $$ | âš¡âš¡ | â­â­â­â­ |
| **2b. Reasoning** | o4-mini | Complex analysis + ReAct | $$$ | âš¡ | â­â­â­â­â­ |
| **3a. Problem Gen** | o4-mini | High-quality problem creation | $$$ | âš¡ | â­â­â­â­â­ |
| **3b. Advice Gen** | gpt-4o | Fast, creative advice | $$ | âš¡âš¡ | â­â­â­â­ |
| **4. Fallback** | o3 | Premium reasoning (rare) | $$$$ | ğŸŒ | â­â­â­â­â­â­ |

### Code: Quality Check â†’ o3 Fallback

```python
# After o4-mini responds
if primary_model == "o4-mini" and not _check_response_quality(response):
    print("âš ï¸ o4-mini quality low, falling back to o3...")

    # Retry with o3 (ìµœê³ ê¸‰ ì¶”ë¡  ëª¨ë¸)
    response = openai.chat.completions.create(
        model="o3",
        messages=messages,
        max_completion_tokens=10000
    )

    print("âœ… o3 response generated successfully")
```

---

## ğŸ¨ Slide 8: Function Calling in Action

### Example 1: Student - Listening Problem

**User Query**: "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"

```python
# GPT-4.1-mini selects function
{
    "function": "generate_problem",
    "arguments": {
        "student_id": "S-01",
        "area": "ë“£ê¸°",
        "difficulty": null  # Auto-detect from student CEFR level
    }
}

# generate_problem function:
# 1. Query student CEFR level from Neo4j â†’ "B1"
# 2. Call o4-mini with detailed prompt
# 3. o4-mini generates dialogue (170-200 words for B2)
# 4. Post-process: Add [AUDIO] + [SPEAKERS] tags
# 5. Call OpenAI TTS API for multi-voice audio
# 6. Return problem + audio URL
```

### Example 2: Teacher - Low-Performing Students

**User Query**: "ë…í•´ 70ì  ë¯¸ë§Œ í•™ìƒë“¤ ë³´ì—¬ì¤˜"

```python
# GPT-4.1-mini selects function
{
    "function": "search_students_by_score",
    "arguments": {
        "area": "ë…í•´",
        "threshold": 70,
        "limit": 20
    }
}

# search_students_by_score function:
# 1. Neo4j Cypher query
# 2. MATCH (s:Student) WHERE s.reading_score < 70
# 3. Return student list with scores
```

### Example 3: Parent - Study Plan

**User Query**: "ì•½ì  ë¶„ì„í•˜ê³  4ì£¼ ê³„íš ì„¸ì›Œì¤˜"

```
ReAct Mode Activated (Complex query)

Step 1:
  Thought: "ìë…€ ì •ë³´ ë¨¼ì € ì¡°íšŒ"
  Action: get_child_info(student_id="S-01")
  Observation: "CEFR B1, ì–´íœ˜ 65ì  (ì•½ì ), ë…í•´ 85ì  (ê°•ì )"

Step 2:
  Thought: "ë§ì¶¤ ê³„íš ìƒì„±"
  Action: recommend_improvement_areas(student_id="S-01", priority="urgent")
  Observation: "4ì£¼ ì–´íœ˜ ì§‘ì¤‘ ê³„íš ì™„ë£Œ"

Final Answer: "ìë…€ì˜ ì–´íœ˜ë ¥ ë³´ê°•ì„ ìœ„í•œ 4ì£¼ ë¡œë“œë§µ..."
```

---

## ğŸ“Š Slide 9: Neo4j GraphRAG Integration

### Graph Schema + Vector Search

```mermaid
graph LR
    subgraph "Vector Search (Qwen3)"
        Q[Query: ë…í•´ ì•½í•œ í•™ìƒ]
        Q -->|Embed 1024-dim| V[Query Vector]
        V -->|Cosine Similarity > 0.7| VS[(Vector Index)]
        VS --> R1[Similar Students]
    end

    subgraph "Graph Traversal (Cypher)"
        S[(Student Node)]
        R1 --> S
        S -->|HAS_ASSESSMENT| A[Assessment<br/>score: 65]
        S -->|HAS_RADAR| RD[RadarScores<br/>reading: 85]
        S -->|ENROLLED_IN| C[Class<br/>class_id: C-01]
        S -->|HAS_HOMEWORK| HW[Homework<br/>completion: 90%]
        C -->|TAUGHT_BY| T[Teacher<br/>teacher_id: T-01]
    end

    subgraph "Context Fusion"
        A --> CTX[Combined RAG Context]
        RD --> CTX
        C --> CTX
        HW --> CTX
        T --> CTX
    end

    subgraph "LLM Generation"
        CTX -->|Enriched Context| GPT[GPT-4.1-mini]
        GPT --> ANS[Personalized Answer]
    end

    style V fill:#f9ca24,stroke:#333,stroke-width:2px
    style VS fill:#6c5ce7,stroke:#333,stroke-width:2px
    style S fill:#4581c1,stroke:#333,stroke-width:3px
    style CTX fill:#00b894,stroke:#333,stroke-width:2px
    style GPT fill:#74aa9c,stroke:#333,stroke-width:2px
```

### GraphRAG Code

```python
def get_rag_context(student_id: str, query_text: str) -> str:
    """Vector Search + Graph Traversal"""

    # 1. Vector Search (Qwen3-Embedding-0.6B)
    query_embedding = get_embedding(query_text)  # 1024-dim

    cypher_vector = """
    MATCH (s:Student)
    WHERE s.embedding IS NOT NULL
    WITH s, vector.similarity.cosine(s.embedding, $query_embedding) AS score
    WHERE score > 0.7
    RETURN s, score
    ORDER BY score DESC
    LIMIT 5
    """

    # 2. Graph Traversal
    cypher_graph = """
    MATCH (s:Student {student_id: $student_id})
    OPTIONAL MATCH (s)-[:HAS_ASSESSMENT]->(assess:Assessment)
    OPTIONAL MATCH (s)-[:HAS_RADAR]->(radar:RadarScores)
    OPTIONAL MATCH (s)-[:ENROLLED_IN]->(c:Class)
    OPTIONAL MATCH (c)<-[:TEACHES]-(t:Teacher)
    RETURN s, collect(assess) as assessments, radar, c, t
    """

    # 3. Context Fusion
    context = f"""
    Student: {student_data['name']} ({student_data['cefr']})
    Weak Areas: {weak_areas}
    Recent Scores: {scores}
    Class: {class_info}
    Teacher: {teacher_name}
    """

    return context
```

---

## ğŸ—£ï¸ Slide 10: Multi-Voice TTS System

### OpenAI TTS + [SPEAKERS] Metadata

```mermaid
graph TB
    D[Dialogue Generated by o4-mini] --> P[Post-Process]

    P --> P1[Add [AUDIO]: tag]
    P --> P2[Generate [SPEAKERS] JSON]
    P --> P3[Assign unique voices]

    P3 --> V{Voice Assignment}

    V -->|Female| VF[Available: Samantha, Karen, Victoria]
    V -->|Male| VM[Available: David, Daniel, Mark]

    VF --> S1[Speaker1: Emma, voice: Samantha]
    VM --> S2[Speaker2: John, voice: David]
    VF --> S3[Speaker3: Sarah, voice: Karen]

    S1 --> JSON[SPEAKERS JSON:<br/>{speakers: [<br/> {name: Emma, gender: female, voice: Samantha},<br/> {name: John, gender: male, voice: David},<br/> {name: Sarah, gender: female, voice: Karen}<br/>]}]
    S2 --> JSON
    S3 --> JSON

    JSON --> TTS[OpenAI TTS API]

    TTS --> T1[Generate Emma lines with Samantha]
    TTS --> T2[Generate John lines with David]
    TTS --> T3[Generate Sarah lines with Karen]

    T1 --> M[Merge Audio Segments]
    T2 --> M
    T3 --> M

    M --> SAVE[Save: /static/audio/abc123.mp3]
    SAVE --> URL[Return: [AUDIO_URL]: /static/audio/abc123.mp3]

    style JSON fill:#ff6b6b,stroke:#333,stroke-width:2px
    style TTS fill:#74aa9c,stroke:#333,stroke-width:3px
    style SAVE fill:#00b894,stroke:#333,stroke-width:2px
```

### [SPEAKERS] JSON Format

```json
{
  "speakers": [
    {
      "name": "Emma",
      "gender": "female",
      "voice": "Samantha"
    },
    {
      "name": "John",
      "gender": "male",
      "voice": "David"
    },
    {
      "name": "Sarah",
      "gender": "female",
      "voice": "Karen"
    }
  ]
}
```

**Critical Rules**:
- Each speaker MUST have a DIFFERENT voice (no duplicates!)
- Female voices: Samantha, Karen, Victoria (3 available)
- Male voices: David, Daniel, Mark (3 available)
- o4-mini automatically assigns based on speaker names

---

## ğŸ¬ Slide 11: Complete User Journey

### Student Dashboard â†’ AI Chat â†’ Problem Solving

```mermaid
sequenceDiagram
    participant U as Student UI
    participant F as React Frontend
    participant B as FastAPI Backend
    participant R as Routing System
    participant A as Student Agent
    participant FC as Function Calls
    participant N as Neo4j
    participant O as o4-mini
    participant T as OpenAI TTS

    U->>F: Click "AI íŠœí„°" button
    F->>B: POST /api/chat/student<br/>{message: "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜", student_id: "S-01"}

    B->>R: Route query
    R->>R: gpt-4o-mini analyzes<br/>"ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"
    R-->>B: Route to: intelligence (simple task)

    B->>A: gpt-4.1-mini + Functions
    A->>A: Parse: area="ë“£ê¸°", difficulty=auto
    A->>FC: ğŸ”§ Call: generate_problem

    FC->>N: Query student CEFR level
    N-->>FC: CEFR: B1

    FC->>O: Generate B1 listening dialogue
    O->>O: ğŸ’­ Create natural conversation<br/>140-170 words, 2 speakers
    O-->>FC: Dialogue + [AUDIO] + [SPEAKERS]

    FC->>FC: Post-process dialogue
    FC->>T: Generate multi-voice audio
    T-->>FC: /static/audio/abc123.mp3

    FC-->>A: Problem + Audio URL
    A-->>B: Response with problem
    B-->>F: JSON response

    F->>F: Parse [AUDIO_URL]
    F->>F: Render audio player + dialogue

    F-->>U: Display:<br/>- Audio Player<br/>- English Dialogue<br/>- Question + 5 Options

    U->>F: Submit answer: "b"
    F->>B: POST /api/chat/student<br/>{message: "bê°€ ë‹µì¸ê°€?"}

    B->>A: gpt-4.1-mini evaluates
    A->>A: Check answer (stored in context)
    A-->>B: "ì •ë‹µì´ì—ìš”! ì˜í–ˆì–´! ğŸ‰<br/>ì´ ë¬¸ì œëŠ”..."

    B-->>F: Response
    F-->>U: Show feedback
```

---

## ğŸ¯ Slide 12: CSAT Parsing Pipeline (100% Accuracy)

### PDF â†’ VLM â†’ LLM â†’ Neo4j

```mermaid
graph LR
    PDF[CSAT PDF<br/>45 problems] -->|opendataloader-pdf| BB[Extract Pages<br/>+ Bounding Boxes]

    BB -->|Page Images| VLM[VLM: o3<br/>Vision-Language Model]

    VLM -->|Extract| E1[Problem Text]
    VLM -->|Extract| E2[Answer Choices a-e]
    VLM -->|Extract| E3[Audio References]
    VLM -->|Extract| E4[Images/Tables]

    E1 --> JSON1[Problem JSON]
    E2 --> JSON1
    E3 --> JSON1
    E4 --> JSON1

    JSON1 -->|Validate| V{Complete?}
    V -->|No| VLM
    V -->|Yes| LLM[LLM: o3<br/>Reasoning Model]

    LLM -->|Classify| C1[CEFR Level<br/>A1-C2]
    LLM -->|Classify| C2[Problem Type<br/>ë“£ê¸°/ë…í•´/ë¬¸ë²•]
    LLM -->|Classify| C3[Skills Required]

    C1 --> JSON2[Enriched JSON]
    C2 --> JSON2
    C3 --> JSON2

    JSON2 -->|Neo4j Cypher| NEO[(Neo4j Database)]

    NEO --> P[Problem Node]
    P -->|HAS_TYPE| PT[ProblemType Node]
    P -->|HAS_SKILL| SK[Skill Node]
    P -->|HAS_CEFR_LEVEL| LV[CEFRLevel Node]

    style VLM fill:#4ecdc4,stroke:#333,stroke-width:3px
    style LLM fill:#95e1d3,stroke:#333,stroke-width:3px
    style NEO fill:#4581c1,stroke:#333,stroke-width:3px
```

### Model Benchmark Results

```
Test: 2026_10_mock CSAT Exam (45 problems)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model      â”‚ Accuracy â”‚ Time     â”‚ Cost Estimate  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ o4-mini    â”‚ 30/45    â”‚ 8m 30s   â”‚ $2.50          â”‚
â”‚            â”‚ (66.7%)  â”‚          â”‚                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-5      â”‚ 0/45     â”‚ N/A      â”‚ N/A            â”‚
â”‚            â”‚ (0%)     â”‚ FAILED   â”‚ (incompatible) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ o3      âœ“  â”‚ 45/45    â”‚ 10m 15s  â”‚ $5.20          â”‚
â”‚            â”‚ (100%)   â”‚          â”‚ PRODUCTION USE â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Selected: o3 (100% accuracy)
```

### Parsing Code

```python
# VLM Extraction (o3)
response = openai.chat.completions.create(
    model="o3",
    messages=[{
        "role": "user",
        "content": [
            {"type": "image_url", "image_url": {"url": page_image}},
            {"type": "text", "text": extraction_prompt}
        ]
    }]
)
# Returns: {"stem": "...", "options": ["a", "b", ...], "answer": "c"}

# LLM Classification (o3)
response = openai.chat.completions.create(
    model="o3",
    messages=[
        {"role": "system", "content": taxonomy_schema},
        {"role": "user", "content": problem_json}
    ]
)
# Returns: {"cefr_level": "B2", "problem_type": "ë…í•´", "skills": ["ì¶”ë¡ "]}

# Neo4j Storage
cypher = """
CREATE (p:Problem {
    problem_id: $problem_id,
    stem: $stem,
    options: $options,
    answer: $answer,
    cefr_level: $cefr_level,
    problem_type: $problem_type
})
"""
```

---

## ğŸ—ï¸ Slide 13: API Router Structure

### FastAPI Modular Design

```
src/api/
â”œâ”€â”€ main.py                    # App entry + lifespan + CORS
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ auth.py               # JWT login/logout
â”‚   â”œâ”€â”€ chat.py               # AI chatbot endpoints
â”‚   â”‚   â”œâ”€â”€ POST /api/chat/student      â†’ StudentAgentService
â”‚   â”‚   â”œâ”€â”€ POST /api/chat/teacher      â†’ TeacherAgentService
â”‚   â”‚   â””â”€â”€ POST /api/chat/parent       â†’ ParentAgentService
â”‚   â”œâ”€â”€ students.py           # Student CRUD
â”‚   â”œâ”€â”€ teachers.py           # Teacher CRUD
â”‚   â”œâ”€â”€ parents.py            # Parent CRUD
â”‚   â”œâ”€â”€ problems.py           # Problem management
â”‚   â”œâ”€â”€ dashboard.py          # Dashboard stats
â”‚   â”œâ”€â”€ classes.py            # Class management
â”‚   â””â”€â”€ audio.py              # TTS audio endpoints
â””â”€â”€ services/
    â”œâ”€â”€ neo4j_service.py      # Neo4j connection singleton
    â””â”€â”€ audio_session_service.py  # Audio file cleanup
```

### Chat Router Code

```python
# src/api/routers/chat.py

@router.post("/student", response_model=ChatResponse)
async def chat_with_student(request: ChatRequest):
    """í•™ìƒ AI ì±—ë´‡ (Function Calling + ReAct)"""

    agent = get_student_agent_service()

    # Intelligent routing + Function calling + ReAct
    result = agent.chat(
        student_id=request.student_id,
        message=request.message,
        chat_history=request.chat_history,
        session_id=request.session_id
    )

    return ChatResponse(
        message=result["message"],
        model_info=result["model_info"],
        quick_replies=result.get("quick_replies", [])
    )

@router.post("/teacher", response_model=ChatResponse)
async def chat_with_teacher(request: ChatRequest):
    """ì„ ìƒë‹˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ (Function Calling + UI Triggers)"""

    agent = get_teacher_agent_service()

    result = agent.chat(
        teacher_id=request.teacher_id,
        message=request.message,
        chat_history=request.chat_history
    )

    # UI panel trigger (exam upload, daily input)
    if "ui_panel" in result:
        return ChatResponse(
            message=result["message"],
            ui_panel=result["ui_panel"],
            ui_data=result["ui_data"]
        )

    return ChatResponse(
        message=result["message"],
        model_info=result["model_info"]
    )
```

---

## ğŸ“ˆ Slide 14: Performance Metrics

### System Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Component                       â”‚ Latency            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Router (gpt-4o-mini)            â”‚ ~100ms             â”‚
â”‚ Intelligence (gpt-4.1-mini)     â”‚ ~1.5s              â”‚
â”‚ Reasoning (o4-mini)             â”‚ ~3-5s              â”‚
â”‚ Fallback (o3)                   â”‚ ~8-10s (rare)      â”‚
â”‚                                 â”‚                    â”‚
â”‚ Vector Search (Qwen3)           â”‚ <100ms             â”‚
â”‚ Graph Traversal (Neo4j)         â”‚ <50ms              â”‚
â”‚ Combined GraphRAG               â”‚ <300ms             â”‚
â”‚                                 â”‚                    â”‚
â”‚ Problem Generation (o4-mini)    â”‚ ~10-15s            â”‚
â”‚ TTS Audio (OpenAI)              â”‚ ~2-3s              â”‚
â”‚                                 â”‚                    â”‚
â”‚ Total Chat Response             â”‚ 2-5s (typical)     â”‚
â”‚ Total w/ Problem Generation     â”‚ 12-18s             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Database Scale:
- Nodes: ~10,000 (Students, Problems, Assessments)
- Relationships: ~50,000
- Vector Index Size: 10MB (1024-dim Ã— 1000 students)
- Query Performance: <100ms (indexed)
```

### Model Usage Distribution (Estimated)

```
gpt-4o-mini (Router):         100% of requests
gpt-4.1-mini (Intelligence):  70% of requests
o4-mini (Reasoning):          25% of requests
o4-mini (Problem Gen):        15% of requests
o3 (Fallback):                <1% of requests (rare)
```

---

## ğŸ“ Slide 15: Key Technical Achievements

### 5 Major Innovations

**1. 100% CSAT Parsing Accuracy**
- Empirical testing: o3 (100%) vs o4-mini (66.7%) vs gpt-5 (0%)
- Fully automated exam processing (45 problems in ~10 minutes)
- VLM + LLM dual-stage pipeline

**2. Intelligent Routing System**
- Dynamic model selection based on query complexity
- gpt-4o-mini router â†’ gpt-4.1-mini (70%) or o4-mini (30%)
- Quality fallback to o3 if o4-mini fails
- Cost optimization: Use expensive models only when needed

**3. ReAct Pattern for Multi-Step Tasks**
- Thought â†’ Action â†’ Observation loop
- Handles complex queries: "ì•½ì  ë¶„ì„í•˜ê³  ê³„íš ì„¸ì›Œì¤˜"
- Max 5 iterations with o4-mini reasoning model
- Auto-detected based on query patterns

**4. Context-Aware Function Calling**
- 8-10 functions per agent role (Student, Teacher, Parent)
- GPT auto-selects appropriate functions
- Dynamic execution: DB queries, AI generation, external APIs
- Seamless integration with Neo4j GraphRAG

**5. Multi-Voice TTS System**
- OpenAI TTS API with voice metadata
- [SPEAKERS] JSON for multi-speaker dialogues
- 6 unique voices (3 female, 3 male)
- Real-time audio generation for listening problems

---

## ğŸš€ Slide 16: Code Highlights

### Highlight 1: Router Decision

```python
# src/student/services/agent_service.py:88

def _route_query(self, message: str, student_id: str) -> str:
    """ì§ˆë¬¸ ì˜ë„ ë¶„ì„ â†’ intelligence vs reasoning ì„ íƒ"""

    routing_prompt = '''**intelligence** (gpt-4.1-mini) - Fast:
- Simple problem requests (ë¬¸ì œ ë‚´ì¤˜)
- Greetings (ì•ˆë…•?)
- Basic function calls (ì ìˆ˜ ë³´ê¸°)

**reasoning** (o4-mini) - Deep thinking:
- In-depth explanations (ì™œ ê·¸ëŸ°ì§€ ì„¤ëª…)
- Multi-step problem solving
- Learning strategy advice

Question: "{message}"
Respond: "intelligence" or "reasoning"'''

    response = openai.chat.completions.create(
        model="gpt-4o-mini",  # Fast, cheap router
        messages=[{"role": "user", "content": routing_prompt}],
        max_tokens=10,
        temperature=0  # Deterministic
    )

    return response.choices[0].message.content.strip()
```

### Highlight 2: ReAct Loop

```python
# src/teacher/services/teacher_agent_service.py:171

def _react_chat(self, teacher_id: str, message: str, max_steps: int = 5):
    """ReAct (Reasoning + Acting) ëª¨ë“œ"""

    messages = [{"role": "system", "content": system_prompt}]
    messages.append({"role": "user", "content": message})

    for step in range(1, max_steps + 1):
        # LLM Reasoning
        response = openai.chat.completions.create(
            model="o4-mini",
            messages=messages,
            tools=self.functions,
            tool_choice="auto"
        )

        assistant_message = response.choices[0].message

        # Thought
        if assistant_message.content:
            print(f"ğŸ’­ Thought: {assistant_message.content}")

        # Action (Function Calling)
        if assistant_message.tool_calls:
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                arguments = json.loads(tool_call.function.arguments)

                print(f"ğŸ”§ Action: {function_name}({arguments})")

                # Execute function
                result = self._execute_function(function_name, arguments)

                print(f"ğŸ“Š Observation: {result[:200]}...")

                # Add to conversation
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": result
                })
        else:
            # Final answer reached
            return assistant_message.content

    # Max steps exceeded
    return "Please refine your question."
```

### Highlight 3: Function Execution

```python
# src/student/services/agent_service.py:1237

def _execute_function(self, function_name: str, arguments: Dict) -> str:
    """Function ì‹¤í–‰ with type classification"""

    # Type classification
    db_functions = ["get_student_context", "recommend_problems"]
    generation_functions = ["generate_problem", "evaluate_writing"]
    external_api_functions = ["lookup_word", "fetch_news", "check_grammar"]

    # Log function type
    if function_name in db_functions:
        print(f"ğŸ“Š DATABASE QUERY: {function_name}")
    elif function_name in generation_functions:
        print(f"ğŸ¤– AI GENERATION: {function_name}")
    elif function_name in external_api_functions:
        print(f"ğŸŒ EXTERNAL API: {function_name}")

    # Execute
    if function_name == "get_student_context":
        return self._get_student_context(**arguments)
    elif function_name == "recommend_problems":
        return self._recommend_problems(**arguments)
    elif function_name == "generate_problem":
        return self._generate_problem(**arguments)  # Uses o4-mini
    # ... more functions
```

---

## ğŸ¨ Gamma Visualization Prompts

### Architecture Diagrams

**Slide 3 (Intelligent Routing)**:
"Create a decision tree diagram showing user query â†’ router (gpt-4o-mini) â†’ intelligence (gpt-4.1-mini) vs reasoning (o4-mini) â†’ quality check â†’ fallback to o3. Use yellow for router, cyan for intelligence, red for reasoning, purple for o3. Add icons for each model."

**Slide 4 (ReAct Pattern)**:
"Create a sequence diagram with 3 columns: ReAct Engine (o4-mini), Functions, Neo4j. Show 3 iteration loops with Thought (ğŸ’­), Action (ğŸ”§), Observation (ğŸ“Š) emojis. Use different colored boxes for each step."

**Slide 5 (Function Calling)**:
"Create a 3-panel layout showing Student Agent (8 functions), Teacher Agent (10 functions), Parent Agent (10 functions). Group functions by type: Database (green), AI Generation (red), External API (blue), UI Trigger (yellow). Use icons."

**Slide 6 (Request Flow)**:
"Create a detailed sequence diagram: Student â†’ Router â†’ Agent â†’ generate_problem â†’ o4-mini â†’ TTS â†’ User. Show each step with latency annotations. Use different colors for each component."

**Slide 9 (GraphRAG)**:
"Create a split-panel diagram: Left side shows vector search (Qwen3 embedding â†’ vector index), Right side shows graph traversal (Student â†’ Assessment â†’ Class â†’ Teacher). Bottom shows context fusion â†’ GPT-4. Use network graph style."

**Slide 10 (Multi-Voice TTS)**:
"Create a flowchart: Dialogue â†’ Post-Process â†’ [SPEAKERS] JSON â†’ Voice Assignment (show 6 voices) â†’ OpenAI TTS API â†’ Merge Audio â†’ Save. Use audio waveform visualizations."

**Slide 12 (CSAT Parsing)**:
"Create a pipeline diagram: PDF â†’ VLM (o3) â†’ Extraction â†’ Validation â†’ LLM (o3) â†’ Classification â†’ Neo4j. Add a benchmark table showing o4-mini 66.7%, gpt-5 0%, o3 100%. Highlight o3 as selected."

---

## ğŸ“ Presentation Script (10-12 minutes)

**Opening (1m)**:
"ClassMateëŠ” CSAT ì˜ì–´ ì‹œí—˜ì„ 100% ì •í™•ë„ë¡œ ìë™ ë¶„ì„í•˜ê³ , OpenAI Function Callingê³¼ ReAct íŒ¨í„´ì„ ê²°í•©í•˜ì—¬ í•™ìƒ-ì„ ìƒë‹˜-í•™ë¶€ëª¨ë¥¼ ìœ„í•œ ë§ì¶¤í˜• AI ì±—ë´‡ì„ ì œê³µí•˜ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤."

**Architecture (2m)**:
"í•µì‹¬ì€ 4ê³„ì¸µ ëª¨ë¸ ì „ëµì…ë‹ˆë‹¤. 1ê³„ì¸µ Routerê°€ ì§ˆë¬¸ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ê³ , 2ê³„ì¸µì—ì„œ intelligence(ë¹ ë¦„) ë˜ëŠ” reasoning(ê¹Šì´)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ë³µì¡í•œ ì§ˆë¬¸ì€ ReAct íŒ¨í„´ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ìµœëŒ€ 5ë‹¨ê³„ì˜ Thoughtâ†’Actionâ†’Observationì„ ë°˜ë³µí•©ë‹ˆë‹¤. í’ˆì§ˆì´ ë‚®ìœ¼ë©´ 4ê³„ì¸µ o3 ëª¨ë¸ë¡œ fallbackí•©ë‹ˆë‹¤."

**Function Calling (2m)**:
"ê° ì—­í• ë³„ë¡œ 8-10ê°œì˜ í•¨ìˆ˜ë¥¼ ì •ì˜í–ˆê³ , GPTê°€ ìƒí™©ì— ë§ê²Œ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤. Student AgentëŠ” ë¬¸ì œ ìƒì„±ê³¼ í‰ê°€, Teacher AgentëŠ” í•™ìƒ ê²€ìƒ‰ê³¼ UI íŠ¸ë¦¬ê±°, Parent AgentëŠ” ì„±ì  ë¶„ì„ê³¼ í•™ìŠµ ì¡°ì–¸ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. í•¨ìˆ˜ëŠ” DB ì¿¼ë¦¬, AI ìƒì„±, ì™¸ë¶€ API 3ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤."

**ReAct Pattern (2m)**:
"'ë…í•´ ì•½í•œ í•™ìƒ ì°¾ì•„ì„œ ê³„íš ì„¸ì›Œì¤˜' ê°™ì€ ë³µì¡í•œ ì§ˆë¬¸ì€ ReAct ëª¨ë“œë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. Step 1ì—ì„œ í•™ìƒì„ ê²€ìƒ‰í•˜ê³ , Step 2ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•˜ê³ , Step 3ì—ì„œ ë§ì¶¤ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤. o4-mini ì¶”ë¡  ëª¨ë¸ì´ ê° ë‹¨ê³„ì—ì„œ ì‚¬ê³ í•˜ê³  í–‰ë™í•©ë‹ˆë‹¤."

**GraphRAG (1.5m)**:
"Neo4j ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Qwen3 ì„ë² ë”©ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰ì„ í•˜ê³ , Cypher ì¿¼ë¦¬ë¡œ ê·¸ë˜í”„ íƒìƒ‰ì„ í•©ë‹ˆë‹¤. í•™ìƒâ†’ì„±ì â†’ë°˜â†’ì„ ìƒë‹˜ ê´€ê³„ë¥¼ ì¢…í•©í•˜ì—¬ 300ms ì´ë‚´ì— ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."

**Technical Achievements (1.5m)**:
"5ê°€ì§€ í•µì‹¬ ì„±ê³¼ì…ë‹ˆë‹¤. ì²«ì§¸, 100% CSAT íŒŒì‹± ì •í™•ë„. ë‘˜ì§¸, Intelligent Routingìœ¼ë¡œ ë¹„ìš© ìµœì í™”. ì…‹ì§¸, ReAct íŒ¨í„´ìœ¼ë¡œ ë‹¤ë‹¨ê³„ ì‘ì—… ì²˜ë¦¬. ë„·ì§¸, Context-Aware Function Calling. ë‹¤ì„¯ì§¸, Multi-Voice TTS ì‹œìŠ¤í…œì…ë‹ˆë‹¤."

**Performance (1m)**:
"ì „ì²´ ì‘ë‹µ ì‹œê°„ì€ 2-5ì´ˆ, ë¬¸ì œ ìƒì„± í¬í•¨ ì‹œ 12-18ì´ˆì…ë‹ˆë‹¤. GraphRAGëŠ” 300ms, Vector SearchëŠ” 100ms ì´ë‚´ì…ë‹ˆë‹¤. ìš”ì²­ì˜ 70%ëŠ” ë¹ ë¥¸ gpt-4.1-minië¡œ, 25%ëŠ” o4-minië¡œ, 1% ë¯¸ë§Œë§Œ o3ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¹„ìš©ì„ ìµœì í™”í–ˆìŠµë‹ˆë‹¤."

**Closing (1m)**:
"ClassMateëŠ” Intelligent Routing, ReAct Pattern, Dynamic Function Callingì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©ì ìš”êµ¬ì— ë§ê²Œ ëª¨ë¸ê³¼ í•¨ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ì°¨ì„¸ëŒ€ êµìœ¡ í”Œë«í¼ì…ë‹ˆë‹¤."

---

## ğŸ­ Slide 16: User Role Feature Comparison (ë©´ì ‘ìš©)

### 3 Specialized Agents, 29 Total Functions

**Architecture Overview**:
```
Student Agent (8 functions)
   â”œâ”€â”€ 2 Unique: í•™ìŠµ ì¤‘ì‹¬ (get_student_context, recommend_problems)
   â”œâ”€â”€ 2 Unique: AI í‰ê°€ (generate_problem, evaluate_writing)
   â””â”€â”€ 4 Shared: ì™¸ë¶€ API (lookup_word, fetch_news, analyze_text_difficulty, check_grammar)

Teacher Agent (10 functions)
   â”œâ”€â”€ 4 Unique: ê´€ë¦¬ (search_students_by_score, search_students_by_behavior, get_my_class_students, get_student_details)
   â”œâ”€â”€ 2 Unique: UI Trigger (trigger_exam_upload_ui, trigger_daily_input_ui)
   â””â”€â”€ 4 Shared: ì™¸ë¶€ API (lookup_word, fetch_news, analyze_text_difficulty, check_grammar)

Parent Agent (11 functions)
   â”œâ”€â”€ 5 Unique: ëª¨ë‹ˆí„°ë§ (get_child_info, analyze_performance, get_study_advice, get_attendance_status, recommend_improvement_areas)
   â”œâ”€â”€ 1 Unique: YouTube (search_youtube)
   â”œâ”€â”€ 1 Shared with Student: generate_problem
   â””â”€â”€ 4 Shared with All: ì™¸ë¶€ API
```

### Complete Function Comparison Matrix

| Function | Student | Teacher | Parent | Type | Model/Target | Key Purpose |
|----------|:-------:|:-------:|:------:|:----:|:-------------|:------------|
| **UNIQUE: Learning** |
| get_student_context | âœ… | âŒ | âŒ | ğŸ“Š DB | Neo4j GraphRAG | ë³¸ì¸ ì •ë³´ + ë²¡í„° ê²€ìƒ‰ |
| recommend_problems | âœ… | âŒ | âŒ | ğŸ“Š DB | Neo4j Cypher | DB ë¬¸ì œ ì¶”ì²œ |
| evaluate_writing | âœ… | âŒ | âŒ | ğŸ¤– AI | o4-mini | ì„œìˆ í˜• í‰ê°€ (100ì ) |
| **UNIQUE: Class Management** |
| get_my_class_students | âŒ | âœ… | âŒ | ğŸ“Š DB | Neo4j Cypher | ë‹´ë‹¹ ë°˜ ëª©ë¡ |
| search_students_by_score | âŒ | âœ… | âŒ | ğŸ“Š DB | Neo4j Cypher | ì„±ì  ê¸°ì¤€ ê²€ìƒ‰ |
| search_students_by_behavior | âŒ | âœ… | âŒ | ğŸ“Š DB | Neo4j Cypher | íƒœë„ ê¸°ì¤€ ê²€ìƒ‰ |
| get_student_details | âŒ | âœ… | âŒ | ğŸ“Š DB | Neo4j GraphRAG | íŠ¹ì • í•™ìƒ ì¡°íšŒ |
| trigger_exam_upload_ui | âŒ | âœ… | âŒ | ğŸ–¥ï¸ UI | Frontend | UI íŒ¨ë„ íŠ¸ë¦¬ê±° |
| trigger_daily_input_ui | âŒ | âœ… | âŒ | ğŸ–¥ï¸ UI | Frontend | ê¸°ë¡ë¶€ UI íŠ¸ë¦¬ê±° |
| **UNIQUE: Parental Monitoring** |
| get_child_info | âŒ | âŒ | âœ… | ğŸ“Š DB | Neo4j GraphRAG | ìë…€ ì •ë³´ ì¡°íšŒ |
| analyze_performance | âŒ | âŒ | âœ… | ğŸ¤– AI | Neo4j + GPT | ì„±ì  ì¶”ì´ ë¶„ì„ |
| get_study_advice | âŒ | âŒ | âœ… | ğŸ¤– AI | gpt-4o | í•™ìŠµ ì¡°ì–¸ (ë¹ ë¥¸ ìƒì„±) |
| get_attendance_status | âŒ | âŒ | âœ… | ğŸ“Š DB | Neo4j Cypher | ì¶œì„/ìˆ™ì œ í˜„í™© |
| recommend_improvement_areas | âŒ | âŒ | âœ… | ğŸ¤– AI | o4-mini | 4ì£¼ í•™ìŠµ ê³„íš |
| search_youtube | âŒ | âŒ | âœ… | ğŸŒ API | YouTube API | êµìœ¡ ì˜ìƒ ì¶”ì²œ |
| **SHARED: Problem Generation** |
| generate_problem | âœ… | âŒ | âœ… | ğŸ¤– AI | o4-mini | ë¬¸ì œ ìƒì„± + TTS |
| **SHARED: External APIs** |
| lookup_word | âœ… | âœ… | âœ… | ğŸŒ API | Free Dictionary | ë‹¨ì–´ ê²€ìƒ‰ |
| fetch_news | âœ… | âœ… | âœ… | ğŸŒ API | NewsAPI | ì˜ì–´ ë‰´ìŠ¤ |
| analyze_text_difficulty | âœ… | âœ… | âœ… | ğŸŒ Lib | textstat | CEFR ë‚œì´ë„ ë¶„ì„ |
| check_grammar | âœ… | âœ… | âœ… | ğŸŒ API | LanguageTool | ë¬¸ë²• ê²€ì‚¬ |

---

## ğŸ¯ Slide 17: Use Case Examples by Role

### ğŸ‘¨â€ğŸ“ Student Use Case: "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"

**Workflow**:
```
1. Router (gpt-4o-mini) â†’ "intelligence" (simple task)
2. gpt-4.1-mini â†’ Call: generate_problem(area="ë“£ê¸°")
3. o4-mini â†’ Generate dialogue (140-170 words for B1)
4. Post-process â†’ Add [AUDIO] + [SPEAKERS] tags
5. OpenAI TTS â†’ Multi-voice (Samantha + David)
6. Return â†’ Problem + /static/audio/abc123.mp3
```

**Why This Matters (Interview Point)**:
"This demonstrates **end-to-end AI pipeline** - from user intent â†’ intelligent routing â†’ reasoning model â†’ post-processing â†’ TTS generation. The system automatically adapts difficulty to student's CEFR level."

---

### ğŸ‘¨â€ğŸ« Teacher Use Case (ReAct): "ë…í•´ ì•½í•œ í•™ìƒ ì°¾ì•„ì„œ ê³„íš ì„¸ì›Œì¤˜"

**ReAct Multi-Step**:
```
Step 1 (Thought â†’ Action â†’ Observation):
  ğŸ’­ Thought: "ë¨¼ì € ë…í•´ ì ìˆ˜ ë‚®ì€ í•™ìƒ ê²€ìƒ‰"
  ğŸ”§ Action: search_students_by_score(area="ë…í•´", threshold=70)
  ğŸ“Š Observation: "ê¹€ë¯¼ì¤€, ì´ì„œìœ¤, ë°•ì§€ìš° 3ëª…"

Step 2:
  ğŸ’­ Thought: "ì²« ë²ˆì§¸ í•™ìƒ ìƒì„¸ ì •ë³´ í•„ìš”"
  ğŸ”§ Action: get_student_details(student_id="S-01")
  ğŸ“Š Observation: "ê¹€ë¯¼ì¤€ - B1, ë…í•´ 65, ì–´íœ˜ 70"

Step 3:
  ğŸ’­ Thought: "ë§ì¶¤ ê³„íš ìƒì„±"
  (ì„ ìƒë‹˜ì´ ì§ì ‘ ê³„íš ì‘ì„±)

Final: "3ëª…ì˜ í•™ìƒë³„ ì•½ì  ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ..."
```

**Why This Matters (Interview Point)**:
"**ReAct Pattern** for complex tasks - LLM breaks down the query into iterative steps. This shows understanding of **LLM orchestration** and **multi-step reasoning** (o4-mini model)."

---

### ğŸ‘ª Parent Use Case: "ìš°ë¦¬ ì•„ì´ ì„±ì  ì–´ë•Œ?"

**Workflow**:
```
1. Router â†’ "intelligence"
2. gpt-4.1-mini â†’ Call: analyze_performance(student_id="S-01")
3. Neo4j + GPT â†’ Analysis:
   - ì˜ì—­ë³„ ì ìˆ˜ (ë¬¸ë²• 85, ì–´íœ˜ 65, ë…í•´ 75)
   - ë˜ë˜ ë¹„êµ (í•™ê¸‰ í‰ê·  ëŒ€ë¹„ +5ì )
   - ì¶”ì´ (ì–´íœ˜ ì§€ë‚œë‹¬ +10ì !)
4. Return: "ì–´íœ˜ê°€ ì•½í•˜ì§€ë§Œ ê¾¸ì¤€íˆ ì„±ì¥ ì¤‘..."
```

**Why This Matters (Interview Point)**:
"**Role-based access control** - Parents see their child only, Teachers see all students. Same API, different permissions. Demonstrates **security design** and **data privacy**."

---

## ğŸ—ï¸ Slide 18: Architectural Insights (ë©´ì ‘ í¬ì¸íŠ¸)

### 1. Separation of Concerns

**Design Decision**:
- Student Agent: í•™ìŠµ ì¤‘ì‹¬ (self-directed)
- Teacher Agent: ê´€ë¦¬ + UI triggers
- Parent Agent: ëª¨ë‹ˆí„°ë§ + YouTube (enriched content)

**Interview Answer**:
"I implemented **role-based function access**. Students shouldn't search all students by score - that's a teacher privilege. This ensures **data privacy** while maintaining **unified architecture**."

---

### 2. Function Type Classification

**Code** (`src/student/services/agent_service.py:1237`):
```python
def _execute_function(self, function_name: str, arguments: Dict) -> str:
    # Type classification
    db_functions = ["get_student_context", "recommend_problems"]
    generation_functions = ["generate_problem", "evaluate_writing"]
    external_api_functions = ["lookup_word", "fetch_news"]

    if function_name in db_functions:
        print(f"ğŸ“Š DATABASE QUERY: {function_name}")
    elif function_name in generation_functions:
        print(f"ğŸ¤– AI GENERATION: {function_name}")
    elif function_name in external_api_functions:
        print(f"ğŸŒ EXTERNAL API: {function_name}")
```

**Benefits**:
- Easy debugging (type-classified logging)
- Performance monitoring (track DB vs AI latency)
- Cost tracking (identify expensive operations)

---

### 3. Dynamic Model Selection per Function

| Function | Model | Reason |
|----------|-------|--------|
| generate_problem | o4-mini | High-quality reasoning for problem creation |
| evaluate_writing | o4-mini | Deep analysis for evaluation |
| get_study_advice | gpt-4o | Fast, creative advice |
| routing | gpt-4o-mini | Cheap, fast analysis |

**Interview Answer**:
"Different functions need different models. Problem generation needs **reasoning** (o4-mini), but advice can use **fast generation** (gpt-4o). This optimizes **cost and latency**."

---

### 4. UI Trigger Pattern (Teacher Only)

**Code** (`src/teacher/services/teacher_agent_service.py:691`):
```python
def _trigger_exam_upload_ui(self, exam_type: str = "ì¼ë°˜") -> str:
    return json.dumps({
        "ui_trigger": "exam_upload",
        "exam_type": exam_type,
        "message": f"{exam_type} ì‹œí—˜ì§€ ì—…ë¡œë“œ í™”ë©´ ì—´ì—ˆìŠµë‹ˆë‹¤."
    })
```

**Why This Matters**:
- **Conversational UI**: "ì‹œí—˜ì§€ ì˜¬ë¦´ê²Œ" â†’ Opens upload panel
- **No manual navigation** - AI understands intent
- Reduces clicks, improves UX

---

### 5. Shared Business Logic, Different Context

**Example**: `lookup_word` function
- **Student**: "confidentê°€ ë­ì•¼?" â†’ "ìì‹ ê° ìˆëŠ” (í˜•ìš©ì‚¬)"
- **Teacher**: "confident ì˜ˆë¬¸ ë³´ì—¬ì¤˜" â†’ "She is confident in her abilities."
- **Parent**: "confident ë­ì•¼?" â†’ "ìì‹ ê° ìˆëŠ” (ìë…€ í•™ìŠµìš©)"

**Implementation**:
- Same API call (Free Dictionary)
- **Different system prompts** per role
- Context-aware responses

---

## ğŸ¤ Slide 19: Interview Talking Points

**Q: "Why separate functions by role?"**

**A**: "I implemented **role-based access control (RBAC)** at the function level. Students shouldn't search all studentsâ€”that's a teacher privilege. This ensures **data privacy** and **appropriate permissions** for each user type while maintaining a **unified agent architecture**."

---

**Q: "How do you handle shared functionality?"**

**A**: "I use a **service layer pattern**. Functions like `lookup_word` are in `src/shared/services/`, so all agents call the same API. This follows **DRY principle** and ensures **consistent behavior**. The difference is in **system prompts** and **context**."

---

**Q: "What's the most complex feature?"**

**A**: "**ReAct mode** for multi-step tasks. When a teacher asks 'ë…í•´ ì•½í•œ í•™ìƒ ì°¾ì•„ì„œ ê³„íš ì„¸ì›Œì¤˜', the agent breaks it into 3-5 steps using **Thought â†’ Action â†’ Observation** with o4-mini. This demonstrates my understanding of **LLM orchestration** and **iterative reasoning**."

---

**Q: "How would you scale this to 10,000 users?"**

**A**: "Three areas:
1. **Caching** - Cache Neo4j queries in Redis
2. **Async Processing** - Use Celery for long-running tasks
3. **Model Optimization** - Use smaller models (gpt-4o-mini) for 70% of requests via **intelligent routing**."
