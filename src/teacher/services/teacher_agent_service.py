# -*- coding: utf-8 -*-
"""
Teacher Agent Service
OpenAI Function Calling ê¸°ë°˜ ì„ ìƒë‹˜ ì—…ë¬´ ì§€ì› ì‹œìŠ¤í…œ
"""
from __future__ import annotations
import os
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI
from shared.services import (
    get_graph_rag_service,
    get_dictionary_service,
    get_news_service,
    get_text_analysis_service,
    get_grammar_check_service
)
from shared.prompts import PromptManager


# ANSI ìƒ‰ìƒ ì½”ë“œ
class Colors:
    RESET = '\033[0m'
    BOLD = '\033[1m'

    # ìƒ‰ìƒ
    BLACK = '\033[30m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'

    # ë°°ê²½ìƒ‰
    BG_BLACK = '\033[40m'
    BG_RED = '\033[41m'
    BG_GREEN = '\033[42m'
    BG_YELLOW = '\033[43m'
    BG_BLUE = '\033[44m'
    BG_MAGENTA = '\033[45m'
    BG_CYAN = '\033[46m'
    BG_WHITE = '\033[47m'


def print_box(title: str, content: str, color: str = Colors.CYAN):
    """ë°•ìŠ¤ í˜•íƒœë¡œ ë¡œê·¸ ì¶œë ¥"""
    width = 80
    print(f"\n{color}{'='*width}{Colors.RESET}")
    print(f"{color}{Colors.BOLD}{title.center(width)}{Colors.RESET}")
    print(f"{color}{'='*width}{Colors.RESET}")
    for line in content.split('\n'):
        if line.strip():
            print(f"{color}  {line}{Colors.RESET}")
    print(f"{color}{'='*width}{Colors.RESET}\n")


def print_section(emoji: str, title: str, content: str, color: str = Colors.BLUE):
    """ì„¹ì…˜ í˜•íƒœë¡œ ë¡œê·¸ ì¶œë ¥"""
    print(f"\n{color}{Colors.BOLD}{emoji} {title}{Colors.RESET}")
    print(f"{color}{'-'*60}{Colors.RESET}")
    for line in content.split('\n'):
        if line.strip():
            print(f"{color}  {line}{Colors.RESET}")
    print()


class TeacherAgentService:
    """ì„ ìƒë‹˜ ë§ì¶¤ Function Calling ì—ì´ì „íŠ¸"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.openai_api_key)
        self.graph_rag_service = get_graph_rag_service()

        # Function definitions
        self.functions = self._create_functions()

    def _route_query(self, message: str, teacher_id: str) -> str:
        """
        ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ
        Returns: "intelligence" (gpt-4.1-mini) or "reasoning" (o4-mini/o3)
        """
        routing_prompt = f'''Analyze this teacher's question and choose the appropriate model:

**intelligence** (gpt-4.1-mini) - Fast, cost-effective for:
- Simple student data lookup (ì„±ì  ì¡°íšŒ, ì¶œì„ í™•ì¸, í•™ìƒ ëª©ë¡)
- Direct questions with single answer (ëˆ„ê°€ 1ë“±?, í‰ê·  ëª‡ ì ?)
- Greetings and small talk (ì•ˆë…•í•˜ì„¸ìš”, ìˆ˜ê³ í•˜ì„¸ìš”)
- Basic statistics (í•™ê¸‰ í‰ê· , ì¶œì„ë¥ )
- Function calls only (DB ì¡°íšŒë§Œ í•„ìš”)
Examples: "í•™ìƒ ëª©ë¡ ë³´ì—¬ì¤˜", "ê¹€ë¯¼ì¤€ ì„±ì ì€?", "í•™ê¸‰ í‰ê·  ì ìˆ˜ëŠ”?", "ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ ì¶œì„ë¥ ì€?"

**reasoning** (o4-mini) - Deep thinking for:
- Comparative analysis (í•™ìƒ ê°„ ë¹„êµ, íŠ¸ë Œë“œ ë¶„ì„)
- Class performance insights (í•™ê¸‰ ì „ì²´ íŒ¨í„´ íŒŒì•…)
- Teaching strategy recommendations (ìˆ˜ì—… ê°œì„  ë°©ì•ˆ)
- Intervention planning (ë¶€ì§„ í•™ìƒ ì§€ë„ ê³„íš)
- Multi-student synthesis (ì—¬ëŸ¬ í•™ìƒ ì¢…í•© ë¶„ì„)
Examples: "ê¹€ë¯¼ì¤€ê³¼ ì´ì„œìœ¤ì˜ í•™ìŠµ íŒ¨í„´ì„ ë¹„êµí•´ì¤˜", "í•™ê¸‰ ì „ì²´ì˜ ì•½ì ì„ ë¶„ì„í•˜ê³  ìˆ˜ì—… ê³„íš ì„¸ì›Œì¤˜", "ì„±ì ì´ ë–¨ì–´ì§€ëŠ” í•™ìƒë“¤ì„ ìœ„í•œ ì „ëµì€?", "ìƒìœ„ê¶Œê³¼ í•˜ìœ„ê¶Œì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì´ê³  ì–´ë–»ê²Œ ì¢íê¹Œ?", "ë‹¤ìŒ ë‹¬ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì²œí•´ì¤˜"

Question: "{message}"

Respond with ONLY "intelligence" or "reasoning".'''

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # Cheap, fast router
                messages=[{"role": "user", "content": routing_prompt}],
                max_tokens=10,
                temperature=0
            )
            decision = response.choices[0].message.content.strip().lower()

            # ì‹œê°ì  ë¡œê¹…
            if decision == "intelligence":
                print_section(
                    "ğŸ§ ",
                    "ROUTING DECISION",
                    f"Query: {message[:50]}...\n"
                    f"Model: INTELLIGENCE (gpt-4.1-mini)\n"
                    f"Reason: Fast function calling for simple tasks",
                    Colors.CYAN
                )
            else:
                print_section(
                    "ğŸ§ ",
                    "ROUTING DECISION",
                    f"Query: {message[:50]}...\n"
                    f"Model: REASONING (o4-mini)\n"
                    f"Reason: Deep thinking required for complex analysis",
                    Colors.MAGENTA
                )

            return decision if decision in ["intelligence", "reasoning"] else "intelligence"
        except Exception as e:
            print(f"{Colors.RED}âš ï¸  Routing failed: {e}, defaulting to intelligence{Colors.RESET}")
            return "intelligence"  # Default fallback

    def _needs_react(self, message: str) -> bool:
        """
        ReAct ëª¨ë“œê°€ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨

        ë³µì¡í•œ ì§ˆë¬¸ íŒ¨í„´:
        1. ì—°ê²°ì–´ê°€ ìˆëŠ” ë‹¤ë‹¨ê³„ ì‘ì—…: "~í•˜ê³  ~í•´ì¤˜", "~ì°¾ì•„ì„œ ~í•´ì¤˜"
        2. ìˆœì°¨ì  ì§€ì‹œ: "ë¨¼ì € ~ ê·¸ë‹¤ìŒ ~"
        3. ë™ì‚¬ 3ê°œ ì´ìƒ (ì—¬ëŸ¬ ì‘ì—…)
        """
        import re

        # íŒ¨í„´ 1: ì—°ê²°ì–´ ("í•˜ê³ ", "ì°¾ì•„ì„œ", "í™•ì¸í•˜ê³ " ë“±)
        multi_task_keywords = ['í•˜ê³ ', 'ê·¸ë¦¬ê³ ', 'ì°¾ì•„ì„œ', 'í™•ì¸í•˜ê³ ', 'ì¡°íšŒí•˜ê³ ', 'ì•Œë ¤ì£¼ê³ ', 'ë¶„ì„í•˜ê³ ', 'ì¶”ì²œí•´']
        for keyword in multi_task_keywords:
            if keyword in message and ('í•´ì¤˜' in message or 'ì£¼ì„¸ìš”' in message or 'ì¤˜' in message):
                return True

        # íŒ¨í„´ 2: "ë¨¼ì €...ê·¸ë‹¤ìŒ" ë˜ëŠ” "ë¨¼ì €...ê·¸ë¦¬ê³ "
        if 'ë¨¼ì €' in message and ('ê·¸ë‹¤ìŒ' in message or 'ê·¸ë¦¬ê³ ' in message):
            return True

        # íŒ¨í„´ 3: ë™ì‚¬ 3ê°œ ì´ìƒ
        action_verbs = ['ì°¾', 'ë¶„ì„', 'ì¶”ì²œ', 'í™•ì¸', 'ì¡°íšŒ', 'ê²€ìƒ‰', 'ë¹„êµ', 'ìƒì„±', 'ì„¤ëª…', 'ì•Œë ¤', 'ë³´ì—¬', 'ì„¸ì›Œ']
        verb_count = sum(1 for verb in action_verbs if verb in message)
        if verb_count >= 3:
            return True

        return False

    def _react_chat(
        self,
        teacher_id: str,
        message: str,
        chat_history: Optional[List[Dict[str, str]]] = None,
        max_steps: int = 5
    ) -> Dict[str, Any]:
        """
        ReAct (Reasoning + Acting) ëª¨ë“œë¡œ ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì‘ì—… ì²˜ë¦¬

        Args:
            teacher_id: ì„ ìƒë‹˜ ID
            message: ì„ ìƒë‹˜ì˜ ë©”ì‹œì§€
            chat_history: ì´ì „ ëŒ€í™” ê¸°ë¡
            max_steps: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

        Returns:
            Dict with 'message' and 'model_info'
        """
        print(f"\n{'='*60}")
        print(f"ğŸ”„ ReAct Mode Activated (Teacher)")
        print(f"Query: {message}")
        print(f"{'='*60}\n")

        # System prompt
        system_prompt = PromptManager.get_system_prompt(
            role="teacher_agent",
            model="o4-mini",
            context={"teacher_id": teacher_id}
        )

        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [{"role": "system", "content": system_prompt}]

        if chat_history:
            messages.extend(chat_history)

        messages.append({"role": "user", "content": message})

        used_models = ["gpt-4o-mini (router)", "o4-mini (ReAct)"]

        # ReAct ë£¨í”„
        for step in range(1, max_steps + 1):
            print(f"\n--- ReAct Step {step}/{max_steps} ---")

            # LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="o4-mini",
                messages=messages,
                tools=self.functions,
                tool_choice="auto",
                max_completion_tokens=10000
            )

            assistant_message = response.choices[0].message

            # Thought ì¶œë ¥ (LLMì˜ ì‚¬ê³  ê³¼ì •)
            if assistant_message.content:
                print(f"ğŸ’­ Thought: {assistant_message.content[:200]}...")

            # Function í˜¸ì¶œì´ ìˆìœ¼ë©´ ì‹¤í–‰
            if assistant_message.tool_calls:
                messages.append(assistant_message)

                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)

                    print(f"ğŸ”§ Action: {function_name}({arguments})")

                    # Function ì‹¤í–‰
                    result = self._execute_function(function_name, arguments)

                    print(f"ğŸ“Š Observation: {result[:200]}...")

                    # UI íŠ¸ë¦¬ê±° ì²´í¬
                    ui_trigger = self._parse_ui_trigger(result)
                    if ui_trigger:
                        return {
                            "message": ui_trigger["data"].get("message", ""),
                            "ui_panel": ui_trigger["ui_panel"],
                            "ui_data": ui_trigger["data"],
                            "model_info": {
                                "primary": "o4-mini (ReAct)",
                                "all_used": used_models
                            }
                        }

                    # Observationì„ ë©”ì‹œì§€ì— ì¶”ê°€
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
            else:
                # Final answer (Function í˜¸ì¶œ ì—†ìŒ)
                print(f"âœ… Final Answer Reached")

                content = assistant_message.content or "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                return {
                    "message": content,
                    "model_info": {
                        "primary": "o4-mini (ReAct)",
                        "all_used": used_models
                    }
                }

        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì´ˆê³¼
        print(f"âš ï¸  Max steps ({max_steps}) reached")

        # ë§ˆì§€ë§‰ ì‘ë‹µ ìƒì„±
        final_response = self.client.chat.completions.create(
            model="o4-mini",
            messages=messages,
            max_completion_tokens=10000
        )

        return {
            "message": final_response.choices[0].message.content or "ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.",
            "model_info": {
                "primary": "o4-mini (ReAct)",
                "all_used": used_models
            }
        }

    def _check_response_quality(self, response_text: str) -> bool:
        """
        Check if o4-mini response quality is acceptable
        Returns: True if good, False if needs o3 fallback
        """
        # Bad indicators: too short, generic, error patterns
        if len(response_text) < 50:
            return False
        if "ì£„ì†¡í•©ë‹ˆë‹¤" in response_text and "ì˜¤ë¥˜" in response_text:
            return False
        if response_text.count("...") > 3:  # Too many ellipses = incomplete
            return False
        return True

    def _create_functions(self) -> List[Dict[str, Any]]:
        """OpenAI Function Callingìš© function ì •ì˜"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "get_my_class_students",
                    "description": "ìê¸°ë°˜ í•™ìƒë“¤ì˜ ëª©ë¡ê³¼ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "teacher_id": {
                                "type": "string",
                                "description": "ì„ ìƒë‹˜ ID (ì˜ˆ: T-01)"
                            },
                            "include_details": {
                                "type": "boolean",
                                "description": "ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€ (CEFR ë ˆë²¨, ê°•ì•½ì  ë“±)",
                                "default": False
                            }
                        },
                        "required": ["teacher_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_students_by_score",
                    "description": "í•™ì› ì „ì²´ ë˜ëŠ” íŠ¹ì • ë°˜ì—ì„œ íŠ¹ì • ì˜ì—­ ì ìˆ˜ê°€ ê¸°ì¤€ ë¯¸ë§Œì¸ í•™ìƒë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "area": {
                                "type": "string",
                                "description": "ì˜ì—­: 'ë…í•´'(RD), 'ë¬¸ë²•'(GR), 'ì–´íœ˜'(VO), 'ë“£ê¸°'(LS), 'ì“°ê¸°'(WR)",
                                "enum": ["ë…í•´", "ë¬¸ë²•", "ì–´íœ˜", "ë“£ê¸°", "ì“°ê¸°", "RD", "GR", "VO", "LS", "WR"]
                            },
                            "threshold": {
                                "type": "integer",
                                "description": "ê¸°ì¤€ ì ìˆ˜ (ì˜ˆ: 70ì  ë¯¸ë§Œ â†’ 70)"
                            },
                            "class_id": {
                                "type": "string",
                                "description": "ë°˜ ID (ìƒëµ ì‹œ í•™ì› ì „ì²´ ê²€ìƒ‰)"
                            },
                            "limit": {
                                "type": "integer",
                                "description": "ìµœëŒ€ í•™ìƒ ìˆ˜ (ê¸°ë³¸ 20ëª…)",
                                "default": 20
                            }
                        },
                        "required": ["area", "threshold"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_students_by_behavior",
                    "description": "ìˆ˜ì—… íƒœë„ê°€ ì¢‹ì§€ ì•Šì€ í•™ìƒë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ì¶œì„ë¥  ë‚®ìŒ, ìˆ™ì œ ë¯¸ì œì¶œ ë“±)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "criteria": {
                                "type": "string",
                                "description": "ê²€ìƒ‰ ê¸°ì¤€: 'attendance'(ì¶œì„ë¥ ), 'homework'(ìˆ™ì œ ì™„ë£Œìœ¨), 'both'(ë‘˜ ë‹¤)",
                                "enum": ["attendance", "homework", "both"]
                            },
                            "threshold": {
                                "type": "integer",
                                "description": "ê¸°ì¤€ ë¹„ìœ¨ (ì˜ˆ: 70% ë¯¸ë§Œ â†’ 70)"
                            },
                            "class_id": {
                                "type": "string",
                                "description": "ë°˜ ID (ìƒëµ ì‹œ í•™ì› ì „ì²´ ê²€ìƒ‰)"
                            },
                            "limit": {
                                "type": "integer",
                                "description": "ìµœëŒ€ í•™ìƒ ìˆ˜",
                                "default": 20
                            }
                        },
                        "required": ["criteria", "threshold"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "trigger_exam_upload_ui",
                    "description": "ì‹œí—˜ì§€ ì—…ë¡œë“œ UIë¥¼ ìš°ì¸¡ íŒ¨ë„ì— í‘œì‹œí•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "exam_type": {
                                "type": "string",
                                "description": "ì‹œí—˜ ìœ í˜• (ì¤‘ê°„ê³ ì‚¬, ê¸°ë§ê³ ì‚¬, ëª¨ì˜ê³ ì‚¬ ë“±)",
                                "default": "ì¼ë°˜"
                            }
                        },
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "trigger_daily_input_ui",
                    "description": "í•™ìƒ ê¸°ë¡ë¶€(Daily Input) ì‘ì„± UIë¥¼ ìš°ì¸¡ íŒ¨ë„ì— í‘œì‹œí•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "teacher_id": {
                                "type": "string",
                                "description": "ì„ ìƒë‹˜ ID (ìê¸°ë°˜ í•™ìƒ ë¶ˆëŸ¬ì˜¤ê¸°)"
                            }
                        },
                        "required": ["teacher_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "get_student_details",
                    "description": "íŠ¹ì • í•™ìƒì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "student_id": {
                                "type": "string",
                                "description": "í•™ìƒ ID"
                            }
                        },
                        "required": ["student_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "lookup_word",
                    "description": "ì˜ì–´ ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë°œìŒ, ì •ì˜, ì˜ˆë¬¸, ë™ì˜ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤ (ìˆ˜ì—… ìë£Œ ì¤€ë¹„ìš©)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "word": {
                                "type": "string",
                                "description": "ê²€ìƒ‰í•  ì˜ì–´ ë‹¨ì–´"
                            }
                        },
                        "required": ["word"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "fetch_news",
                    "description": "í•™ìƒë“¤ì—ê²Œ ì¶”ì²œí•  ì˜ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ì½ê¸° ìë£Œ ì¤€ë¹„ìš©)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "category": {
                                "type": "string",
                                "description": "ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬",
                                "enum": ["general", "sports", "technology", "health", "science", "entertainment"],
                                "default": "general"
                            },
                            "page_size": {
                                "type": "integer",
                                "description": "ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜ (1-10)",
                                "default": 3,
                                "minimum": 1,
                                "maximum": 10
                            }
                        },
                        "required": []
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "analyze_text_difficulty",
                    "description": "í…ìŠ¤íŠ¸ì˜ ë‚œì´ë„(CEFR ë ˆë²¨)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ìˆ˜ì—… ìë£Œ ë‚œì´ë„ ì¸¡ì •ìš©)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "ë¶„ì„í•  ì˜ì–´ í…ìŠ¤íŠ¸"
                            }
                        },
                        "required": ["text"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "check_grammar",
                    "description": "ì˜ì–´ ë¬¸ì¥ì˜ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ê²€ì‚¬í•©ë‹ˆë‹¤ (ìˆ˜ì—… ìë£Œ ê²€í† ìš©)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "text": {
                                "type": "string",
                                "description": "ê²€ì‚¬í•  ì˜ì–´ í…ìŠ¤íŠ¸"
                            }
                        },
                        "required": ["text"]
                    }
                }
            }
        ]

    def _get_my_class_students(self, teacher_id: str, include_details: bool = False) -> str:
        """ìê¸°ë°˜ í•™ìƒ ì¡°íšŒ"""
        try:
            # Neo4jì—ì„œ ì„ ìƒë‹˜ì˜ ë°˜ ì •ë³´ ì¡°íšŒ
            from pathlib import Path

            # 1. teachers.jsonì—ì„œ ë‹´ë‹¹ ë°˜ ì¡°íšŒ
            teachers_file = Path("/home/sh/projects/ClassMate/data/json/teachers.json")
            with open(teachers_file, "r", encoding="utf-8") as f:
                teachers_data = json.load(f)

            assigned_classes = []
            teacher_name = None
            for teacher in teachers_data:
                if teacher["teacher_id"] == teacher_id:
                    assigned_classes = teacher["assigned_classes"]
                    teacher_name = teacher["name"]
                    break

            if not assigned_classes:
                return f"ì„ ìƒë‹˜ {teacher_id}ì˜ ë‹´ë‹¹ ë°˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # 2. Neo4jì—ì„œ í•´ë‹¹ ë°˜ í•™ìƒë“¤ ì¡°íšŒ
            driver = self.graph_rag_service._get_driver()
            database = self.graph_rag_service.neo4j_db
            with driver.session(database=database) as session:
                result = session.run("""
                    MATCH (s:Student)
                    WHERE s.class_id IN $class_ids
                    RETURN s.student_id as student_id,
                           s.name as name,
                           s.grade_label as grade_label,
                           s.cefr as cefr,
                           s.class_id as class_id,
                           s.grammar_score as grammar_score,
                           s.vocabulary_score as vocabulary_score,
                           s.reading_score as reading_score,
                           s.listening_score as listening_score,
                           s.writing_score as writing_score,
                           s.attendance_rate as attendance_rate,
                           s.homework_completion_rate as homework_rate
                    ORDER BY s.student_id
                """, class_ids=assigned_classes)

                students = []
                for record in result:
                    student_info = {
                        "student_id": record["student_id"],
                        "name": record["name"],
                        "grade": record["grade_label"],
                        "cefr": record["cefr"],
                        "class_id": record["class_id"]
                    }

                    if include_details:
                        student_info.update({
                            "grammar": record.get("grammar_score"),
                            "vocabulary": record.get("vocabulary_score"),
                            "reading": record.get("reading_score"),
                            "listening": record.get("listening_score"),
                            "writing": record.get("writing_score"),
                            "attendance_rate": record.get("attendance_rate"),
                            "homework_rate": record.get("homework_rate")
                        })

                    students.append(student_info)

            if not students:
                return f"{teacher_name} ì„ ìƒë‹˜ì˜ ë‹´ë‹¹ ë°˜({', '.join(assigned_classes)})ì— í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤."

            # ê²°ê³¼ í¬ë§·íŒ…
            response = f"**{teacher_name} ì„ ìƒë‹˜ì˜ ë‹´ë‹¹ í•™ìƒ ëª©ë¡** (ì´ {len(students)}ëª…)\n"
            response += f"**ë‹´ë‹¹ ë°˜:** {', '.join(assigned_classes)}\n\n"

            for i, student in enumerate(students, 1):
                response += f"{i}. **{student['name']}** ({student['student_id']})\n"
                response += f"   - í•™ë…„: {student['grade']}\n"
                response += f"   - CEFR ë ˆë²¨: {student['cefr']}\n"

                if include_details:
                    response += f"   - ì˜ì—­ë³„ ì ìˆ˜: ë¬¸ë²• {student.get('grammar', 'N/A')}, ì–´íœ˜ {student.get('vocabulary', 'N/A')}, ë…í•´ {student.get('reading', 'N/A')}, ë“£ê¸° {student.get('listening', 'N/A')}, ì“°ê¸° {student.get('writing', 'N/A')}\n"
                    response += f"   - ì¶œì„ë¥ : {student.get('attendance_rate', 'N/A')}%, ìˆ™ì œ ìˆ˜í–‰ë¥ : {student.get('homework_rate', 'N/A')}%\n"

                response += "\n"

            return response

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"[ERROR] _get_my_class_students failed: {error_details}")
            return f"í•™ìƒ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _search_students_by_score(
        self,
        area: str,
        threshold: int,
        class_id: Optional[str] = None,
        limit: int = 20
    ) -> str:
        """ì ìˆ˜ ê¸°ì¤€ í•™ìƒ ê²€ìƒ‰"""
        try:
            # Area í•œê¸€ â†’ ì½”ë“œ ë³€í™˜
            area_map = {
                "ë…í•´": "RD", "ë¬¸ë²•": "GR", "ì–´íœ˜": "VO",
                "ë“£ê¸°": "LS", "ì“°ê¸°": "WR"
            }
            area_code = area_map.get(area, area.upper())

            # TODO: Neo4j Cypher ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
            # ì˜ˆ: MATCH (s:Student) WHERE s.rd_score < threshold RETURN s

            # ì„ì‹œ: GraphRAGë¡œ ê²€ìƒ‰
            query = f"{area} ì ìˆ˜ê°€ {threshold}ì  ë¯¸ë§Œì¸ í•™ìƒë“¤"
            if class_id:
                query += f" (ë°˜: {class_id})"

            context = self.graph_rag_service.get_rag_context(
                student_id=None,
                query_text=query,
                use_vector_search=True
            )

            return context

        except Exception as e:
            return f"í•™ìƒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

    def _search_students_by_behavior(
        self,
        criteria: str,
        threshold: int,
        class_id: Optional[str] = None,
        limit: int = 20
    ) -> str:
        """íƒœë„ ê¸°ì¤€ í•™ìƒ ê²€ìƒ‰"""
        try:
            # TODO: Neo4j Cypher ì¿¼ë¦¬
            # ì˜ˆ: MATCH (s:Student) WHERE s.attendance_rate < threshold

            criteria_map = {
                "attendance": "ì¶œì„ë¥ ",
                "homework": "ìˆ™ì œ ì™„ë£Œìœ¨",
                "both": "ì¶œì„ë¥ ê³¼ ìˆ™ì œ ì™„ë£Œìœ¨"
            }
            criteria_kr = criteria_map.get(criteria, criteria)

            query = f"{criteria_kr}ì´ {threshold}% ë¯¸ë§Œì¸ í•™ìƒë“¤"
            if class_id:
                query += f" (ë°˜: {class_id})"

            context = self.graph_rag_service.get_rag_context(
                student_id=None,
                query_text=query,
                use_vector_search=True
            )

            return context

        except Exception as e:
            return f"í•™ìƒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

    def _trigger_exam_upload_ui(self, exam_type: str = "ì¼ë°˜") -> str:
        """ì‹œí—˜ì§€ ì—…ë¡œë“œ UI íŠ¸ë¦¬ê±°"""
        # íŠ¹ìˆ˜ ì‘ë‹µ í¬ë§· ë°˜í™˜
        return json.dumps({
            "ui_trigger": "exam_upload",
            "exam_type": exam_type,
            "message": f"{exam_type} ì‹œí—˜ì§€ ì—…ë¡œë“œ í™”ë©´ì„ ì—´ì—ˆìŠµë‹ˆë‹¤."
        })

    def _trigger_daily_input_ui(self, teacher_id: str) -> str:
        """ê¸°ë¡ë¶€ ì‘ì„± UI íŠ¸ë¦¬ê±°"""
        return json.dumps({
            "ui_trigger": "daily_input",
            "teacher_id": teacher_id,
            "message": "í•™ìƒ ê¸°ë¡ë¶€ ì‘ì„± í™”ë©´ì„ ì—´ì—ˆìŠµë‹ˆë‹¤."
        })

    def _get_student_details(self, student_id: str) -> str:
        """í•™ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            context = self.graph_rag_service.get_rag_context(
                student_id=student_id,
                query_text=f"{student_id} í•™ìƒì˜ ìƒì„¸ ì •ë³´",
                use_vector_search=True
            )
            return context
        except Exception as e:
            return f"í•™ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

    def _lookup_word(self, word: str) -> str:
        """ì˜ì–´ ë‹¨ì–´ ê²€ìƒ‰ (Free Dictionary API)"""
        try:
            service = get_dictionary_service()
            result = service.lookup_word(word)

            if not result.get('success'):
                return f"ë‹¨ì–´ '{word}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì² ìë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

            # ê²°ê³¼ í¬ë§·íŒ…
            response = f"**{result['word']}** {result.get('phonetic', '')}\n\n"
            response += f"**í’ˆì‚¬:** {result.get('part_of_speech', 'N/A')}\n\n"
            response += f"**ì •ì˜:** {result.get('definition', 'N/A')}\n\n"

            if result.get('example'):
                response += f"**ì˜ˆë¬¸:** {result['example']}\n\n"

            if result.get('synonyms'):
                synonyms = ', '.join(result['synonyms'])
                response += f"**ë™ì˜ì–´:** {synonyms}\n\n"

            if result.get('antonyms'):
                antonyms = ', '.join(result['antonyms'])
                response += f"**ë°˜ì˜ì–´:** {antonyms}\n\n"

            phonetics = result.get('phonetics', [])
            audio_urls = [p['audio'] for p in phonetics if p.get('audio')]
            if audio_urls:
                response += f"**ë°œìŒ ë“£ê¸°:** {audio_urls[0]}\n"

            return response
        except Exception as e:
            return f"ë‹¨ì–´ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

    def _fetch_news(self, category: str = "general", page_size: int = 3) -> str:
        """ì˜ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ ê²€ìƒ‰ (NewsAPI)"""
        try:
            service = get_news_service()
            result = service.fetch_news(
                category=category,
                language="en",
                page_size=min(page_size, 5),
                country="us"
            )

            if not result.get('success'):
                error_msg = result.get('error', 'Unknown error')
                if "NEWS_API_KEY not configured" in error_msg:
                    return "ë‰´ìŠ¤ APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
                return f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {error_msg}"

            articles = result.get('articles', [])
            if not articles:
                return f"'{category}' ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # ê¸°ì‚¬ í¬ë§·íŒ…
            response = f"**{category.title()} ì¹´í…Œê³ ë¦¬ ìµœì‹  ë‰´ìŠ¤** ({len(articles)}ê°œ)\n\n"

            for i, article in enumerate(articles, 1):
                response += f"**{i}. {article['title']}**\n"
                response += f"   *ì¶œì²˜:* {article['source']}\n"
                if article.get('description'):
                    response += f"   *ìš”ì•½:* {article['description']}\n"
                response += f"   *ë§í¬:* {article['url']}\n\n"

            return response
        except Exception as e:
            return f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"

    def _analyze_text_difficulty(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ë‚œì´ë„ ë¶„ì„ (textstat)"""
        try:
            service = get_text_analysis_service()
            result = service.analyze_cefr_level(text)

            if not result.get('success'):
                error_msg = result.get('error', 'Unknown error')
                if "textstat library not installed" in error_msg:
                    return "í…ìŠ¤íŠ¸ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
                return f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {error_msg}"

            # ê²°ê³¼ í¬ë§·íŒ…
            response = f"**í…ìŠ¤íŠ¸ ë‚œì´ë„ ë¶„ì„ ê²°ê³¼**\n\n"
            response += f"**CEFR ë ˆë²¨:** {result['cefr_level']}\n"
            response += f"**ë‚œì´ë„:** {result['difficulty']}\n"
            response += f"**ê°€ë…ì„± ì ìˆ˜ (Flesch):** {result['flesch_reading_ease']}/100 (ë†’ì„ìˆ˜ë¡ ì‰¬ì›€)\n"
            response += f"**í•™ë…„ ìˆ˜ì¤€ (FK Grade):** {result['flesch_kincaid_grade']}í•™ë…„\n\n"
            response += f"**í†µê³„:**\n"
            response += f"- ë‹¨ì–´ ìˆ˜: {result['word_count']}ê°œ\n"
            response += f"- ë¬¸ì¥ ìˆ˜: {result['sentence_count']}ê°œ\n"
            response += f"- í‰ê·  ë¬¸ì¥ ê¸¸ì´: {result['avg_sentence_length']}ë‹¨ì–´\n\n"

            level_descriptions = {
                "A1": "ì´ˆê¸‰ - ë§¤ìš° ì‰¬ìš´ í…ìŠ¤íŠ¸",
                "A2": "ì´ˆê¸‰ ìƒ - ì‰¬ìš´ í…ìŠ¤íŠ¸",
                "B1": "ì¤‘ê¸‰ - ë³´í†µ ë‚œì´ë„ í…ìŠ¤íŠ¸",
                "B2": "ì¤‘ê¸‰ ìƒ - ì–´ë ¤ìš´ í…ìŠ¤íŠ¸",
                "C1": "ê³ ê¸‰ - ë§¤ìš° ì–´ë ¤ìš´ í…ìŠ¤íŠ¸",
                "C2": "ê³ ê¸‰ ìƒ - ì „ë¬¸ê°€ ìˆ˜ì¤€ í…ìŠ¤íŠ¸"
            }
            response += f"**ë ˆë²¨ ì„¤ëª…:** {level_descriptions.get(result['cefr_level'], 'N/A')}\n"

            return response
        except Exception as e:
            return f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"

    def _check_grammar(self, text: str) -> str:
        """ë¬¸ë²• ê²€ì‚¬ (LanguageTool API)"""
        try:
            service = get_grammar_check_service()
            result = service.check_grammar(text, language="en-US")

            if not result.get('success'):
                return f"ë¬¸ë²• ê²€ì‚¬ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}"

            error_count = result.get('error_count', 0)
            errors = result.get('errors', [])

            if error_count == 0:
                return "**ë¬¸ë²• ê²€ì‚¬ ê²°ê³¼:** ë¬¸ë²• ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤! âœ…"

            # ì˜¤ë¥˜ í¬ë§·íŒ…
            response = f"**ë¬¸ë²• ê²€ì‚¬ ê²°ê³¼:** {error_count}ê°œì˜ ì˜¤ë¥˜ ë°œê²¬\n\n"

            for i, error in enumerate(errors[:10], 1):
                response += f"**{i}. {error['message']}**\n"

                offset = error['offset']
                length = error['length']
                error_text = text[offset:offset+length]
                response += f"   *ë¬¸ì œ:* \"{error_text}\"\n"

                replacements = error.get('replacements', [])
                if replacements:
                    suggestions = ', '.join([f'"{r}"' for r in replacements])
                    response += f"   *ì œì•ˆ:* {suggestions}\n"

                category = error.get('category', '')
                if category:
                    response += f"   *ìœ í˜•:* {category}\n"

                response += "\n"

            if error_count > 10:
                response += f"*({error_count - 10}ê°œ ì˜¤ë¥˜ ë” ìˆìŒ)*\n"

            return response
        except Exception as e:
            return f"ë¬¸ë²• ê²€ì‚¬ ì‹¤íŒ¨: {str(e)}"

    def _execute_function(self, function_name: str, arguments: Dict[str, Any]) -> str:
        """Function ì‹¤í–‰"""

        # í•¨ìˆ˜ íƒ€ì… ë¶„ë¥˜
        db_functions = ["get_my_class_students", "search_students_by_score", "search_students_by_behavior", "get_student_details"]
        ui_trigger_functions = ["trigger_exam_upload_ui", "trigger_daily_input_ui"]
        external_api_functions = ["lookup_word", "fetch_news", "analyze_text_difficulty", "check_grammar"]

        if function_name in db_functions:
            func_type = "ğŸ“Š DATABASE QUERY"
            color = Colors.GREEN
        elif function_name in ui_trigger_functions:
            func_type = "ğŸ–¥ï¸ UI TRIGGER"
            color = Colors.YELLOW
        elif function_name in external_api_functions:
            func_type = "ğŸŒ EXTERNAL API"
            color = Colors.BLUE
        else:
            func_type = "â“ UNKNOWN"
            color = Colors.RED

        print_section(
            "ğŸ”§",
            f"FUNCTION CALL - {func_type}",
            f"Function: {function_name}\n"
            f"Arguments: {json.dumps(arguments, ensure_ascii=False, indent=2)}",
            color
        )

        if function_name == "get_my_class_students":
            result = self._get_my_class_students(**arguments)
        elif function_name == "search_students_by_score":
            result = self._search_students_by_score(**arguments)
        elif function_name == "search_students_by_behavior":
            result = self._search_students_by_behavior(**arguments)
        elif function_name == "trigger_exam_upload_ui":
            result = self._trigger_exam_upload_ui(**arguments)
        elif function_name == "trigger_daily_input_ui":
            result = self._trigger_daily_input_ui(**arguments)
        elif function_name == "get_student_details":
            result = self._get_student_details(**arguments)
        elif function_name == "lookup_word":
            result = self._lookup_word(**arguments)
        elif function_name == "fetch_news":
            result = self._fetch_news(**arguments)
        elif function_name == "analyze_text_difficulty":
            result = self._analyze_text_difficulty(**arguments)
        elif function_name == "check_grammar":
            result = self._check_grammar(**arguments)
        else:
            result = f"Unknown function: {function_name}"

        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
        result_preview = result[:200] + "..." if len(result) > 200 else result
        print(f"{Colors.GREEN}âœ… Function completed: {result_preview}{Colors.RESET}\n")

        return result

    def _parse_ui_trigger(self, content: str) -> Optional[Dict[str, Any]]:
        """
        Function ì‘ë‹µì—ì„œ UI íŠ¸ë¦¬ê±° ì¶”ì¶œ

        Returns:
            {"ui_panel": "exam_upload" | "daily_input", "data": {...}} ë˜ëŠ” None
        """
        try:
            data = json.loads(content)
            if "ui_trigger" in data:
                return {
                    "ui_panel": data["ui_trigger"],
                    "data": data
                }
        except:
            pass
        return None

    def chat(
        self,
        teacher_id: str,
        message: str,
        chat_history: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """
        ì„ ìƒë‹˜ê³¼ ì±„íŒ… (Function Calling with Intelligent Routing)

        Args:
            teacher_id: ì„ ìƒë‹˜ ID
            message: ì„ ìƒë‹˜ì˜ ë©”ì‹œì§€
            chat_history: ì´ì „ ëŒ€í™” ê¸°ë¡

        Returns:
            Dict with 'message', 'model_info', and optionally 'ui_panel'
        """
        try:
            # ========== ìš”ì²­ ì‹œì‘ ë¡œê¹… ==========
            print_box(
                "ğŸ‘¨â€ğŸ« TEACHER CHATBOT REQUEST",
                f"Teacher ID: {teacher_id}\n"
                f"Message: {message}",
                Colors.BLUE
            )

            # ReAct ëª¨ë“œ íŒë‹¨ (ë³µì¡í•œ ë‹¤ë‹¨ê³„ ì§ˆë¬¸)
            if self._needs_react(message):
                return self._react_chat(teacher_id, message, chat_history)

            used_models = []  # Track models used

            # Step 1: Route the query to determine complexity
            routing_decision = self._route_query(message, teacher_id)
            used_models.append("gpt-4o-mini")  # Router model

            # Step 2: Select primary model based on routing decision
            if routing_decision == "reasoning":
                primary_model = "o4-mini"
                print(f"ğŸ¯ Using reasoning model: {primary_model}")
            else:
                primary_model = "gpt-4.1-mini"
                print(f"ğŸ¯ Using intelligence model: {primary_model}")

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (PromptManager ì‚¬ìš©)
            system_prompt = PromptManager.get_system_prompt(
                role="teacher_agent",
                model=primary_model,
                context={"teacher_id": teacher_id}
            )

            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": system_prompt}]

            if chat_history:
                messages.extend(chat_history)

            messages.append({"role": "user", "content": message})

            # Step 3: Call primary model with function calling
            used_models.append(primary_model)

            # Use appropriate parameters based on model type
            if primary_model == "o4-mini":
                # o4-mini uses max_completion_tokens
                response = self.client.chat.completions.create(
                    model="o4-mini",
                    messages=messages,
                    tools=self.functions,
                    tool_choice="auto",
                    max_completion_tokens=10000
                )
            else:
                # gpt-4.1-mini uses max_tokens
                response = self.client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=messages,
                    tools=self.functions,
                    tool_choice="auto",
                    temperature=0.7
                )

            assistant_message = response.choices[0].message

            # Function í˜¸ì¶œ ì²˜ë¦¬
            if assistant_message.tool_calls:
                messages.append(assistant_message)

                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)

                    print(f"ğŸ”§ Function Call: {function_name}({arguments})")

                    # Function ì‹¤í–‰
                    function_response = self._execute_function(function_name, arguments)

                    # UI íŠ¸ë¦¬ê±° ì²´í¬
                    ui_trigger = self._parse_ui_trigger(function_response)

                    if ui_trigger:
                        # UI íŠ¸ë¦¬ê±°ì¸ ê²½ìš° ì¦‰ì‹œ ë°˜í™˜
                        return {
                            "message": ui_trigger["data"].get("message", ""),
                            "ui_panel": ui_trigger["ui_panel"],
                            "ui_data": ui_trigger["data"],
                            "model_info": {
                                "primary": primary_model,
                                "all_used": list(set(used_models))
                            }
                        }

                    # Function ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": function_response
                    })

                # ìµœì¢… ì‘ë‹µ ìƒì„±
                # Use the same model as primary for consistency
                if primary_model == "o4-mini":
                    final_response = self.client.chat.completions.create(
                        model="o4-mini",
                        messages=messages,
                        max_completion_tokens=10000
                    )
                else:
                    final_response = self.client.chat.completions.create(
                        model="gpt-4.1-mini",
                        messages=messages,
                        temperature=0.7
                    )

                response_content = final_response.choices[0].message.content

                # Step 4: Quality check for o4-mini responses
                if primary_model == "o4-mini" and not self._check_response_quality(response_content):
                    print(f"âš ï¸  o4-mini response quality low, falling back to o3...")
                    used_models.append("o3")

                    # Retry with o3 (advanced reasoning)
                    try:
                        final_response_o3 = self.client.chat.completions.create(
                            model="o3",
                            messages=messages,
                            max_completion_tokens=10000
                        )
                        response_content = final_response_o3.choices[0].message.content
                        primary_model = "o3"  # Update primary model
                        print(f"âœ… o3 response generated successfully")
                    except Exception as e:
                        print(f"âš ï¸  o3 fallback failed: {e}, using o4-mini response anyway")

                return {
                    "message": response_content,
                    "model_info": {
                        "primary": primary_model,
                        "all_used": list(set(used_models))
                    }
                }
            else:
                # Function í˜¸ì¶œ ì—†ì´ ì§ì ‘ ì‘ë‹µ
                response_content = assistant_message.content

                # Step 4: Quality check for o4-mini responses (no function calls)
                if primary_model == "o4-mini" and not self._check_response_quality(response_content):
                    print(f"âš ï¸  o4-mini response quality low, falling back to o3...")
                    used_models.append("o3")

                    # Retry with o3 (advanced reasoning)
                    try:
                        final_response_o3 = self.client.chat.completions.create(
                            model="o3",
                            messages=messages,
                            max_completion_tokens=10000
                        )
                        response_content = final_response_o3.choices[0].message.content
                        primary_model = "o3"  # Update primary model
                        print(f"âœ… o3 response generated successfully")
                    except Exception as e:
                        print(f"âš ï¸  o3 fallback failed: {e}, using o4-mini response anyway")

                return {
                    "message": response_content,
                    "model_info": {
                        "primary": primary_model,
                        "all_used": list(set(used_models))
                    }
                }

        except Exception as e:
            return {
                "message": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "model_info": {"primary": "error", "all_used": []}
            }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_teacher_agent_service = None


def get_teacher_agent_service() -> TeacherAgentService:
    """Teacher Agent ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _teacher_agent_service
    if _teacher_agent_service is None:
        _teacher_agent_service = TeacherAgentService()
    return _teacher_agent_service
