"""
TTS Service - OpenAI TTS APIë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ìŒì„± ìƒì„± ë° íš¨ê³¼ìŒ ë¯¹ì‹±
"""
import os
import re
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from openai import OpenAI
from datetime import datetime

# pydubëŠ” íš¨ê³¼ìŒ ë¯¹ì‹±ì—ë§Œ ì‚¬ìš© (ì„ íƒì )
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False
    print("âš ï¸  pydub not available - audio mixing disabled")


class TTSService:
    """OpenAI TTSë¥¼ ì‚¬ìš©í•œ ë“£ê¸° ë¬¸ì œ ìŒì„± ìƒì„±"""

    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.audio_dir = Path('/home/sh/projects/ClassMate/static/audio')
        self.effects_dir = Path('/home/sh/projects/ClassMate/static/effects')

        # ìŒì„± ë§¤í•‘ (OpenAI TTS ìŒì„±)
        self.voice_map = {
            'Samantha': 'nova',      # Female - warm
            'Karen': 'shimmer',      # Female - gentle
            'Victoria': 'alloy',     # Female - neutral
            'David': 'onyx',         # Male - deep
            'Daniel': 'echo',        # Male - clear
            'Mark': 'fable',         # Male - expressive
        }

        # íš¨ê³¼ìŒ íŒŒì¼ ë§¤í•‘ (ì¹´í…Œê³ ë¦¬ë³„ë¡œ êµ¬ì„±)
        self.effects = {
            # ê¸°ì¡´ íš¨ê³¼ìŒ (í˜¸í™˜ì„± ìœ ì§€)
            'phone_ring': 'phone_ring.mp3',
            'cafe_ambient': 'cafe_ambient.mp3',
            'office_ambient': 'office_ambient.mp3',
            'outdoor_ambient': 'outdoor_ambient.mp3',

            # ì „í™”Â·ë©”ì‹œì§€
            'smartphone_ring': 'smartphone_ring.mp3',
            'text_notification': 'text_notification.mp3',
            'call_connect': 'call_connect.mp3',

            # ë¬¸Â·ì¶œì…
            'doorbell': 'doorbell.mp3',
            'door_knock': 'door_knock.mp3',
            'door_open_close': 'door_open_close.mp3',

            # í•™êµÂ·ì‚¬ë¬´
            'school_bell': 'school_bell.mp3',
            'keyboard_typing': 'keyboard_typing.mp3',
            'paper_shuffle': 'paper_shuffle.mp3',

            # ìƒì Â·ì¹´í˜
            'cash_register': 'cash_register.mp3',
            'coffee_machine': 'coffee_machine.mp3',

            # êµí†µÂ·ì•ˆë‚´
            'subway_announcement': 'subway_announcement.mp3',
            'airport_boarding': 'airport_boarding.mp3',

            # ìì—°Â·ì•¼ì™¸
            'rain': 'rain.mp3',
            'birds_chirping': 'birds_chirping.mp3',

            # ë³‘ì›
            'hospital_ambient': 'hospital_ambient.mp3',

            # ì‹œí—˜ ì „ìš©
            'test_start_tone': 'test_start_tone.mp3',
            'test_end_tone': 'test_end_tone.mp3',
        }

    def parse_listening_problem(self, content: str) -> Tuple[List[Dict], Optional[str], Optional[str]]:
        """
        ë“£ê¸° ë¬¸ì œì—ì„œ [SPEAKERS]ì™€ [AUDIO] íŒŒì‹±

        Returns:
            (speakers, audio_text, effect_type)
        """
        speakers = []
        audio_text = None
        effect_type = None

        # [SPEAKERS]: íŒŒì‹±
        speakers_match = re.search(r'\[SPEAKERS\]:\s*(.+?)(?:\n|$)', content)
        if speakers_match:
            try:
                speakers_json = json.loads(speakers_match.group(1).strip())
                speakers = speakers_json.get('speakers', [])
            except json.JSONDecodeError as e:
                print(f"âš ï¸ Failed to parse [SPEAKERS]: {e}")

        # [AUDIO]: íŒŒì‹± (ëŒ€í™” í…ìŠ¤íŠ¸)
        # Extract from [AUDIO]: until question starts (What/Where/When/etc or a)/b)/c)
        audio_match = re.search(
            r'\[AUDIO\]:(.*?)(?=\n(?:What|Where|When|Who|Why|How) |\n[a-e]\)|\[Question\]|$)',
            content,
            re.DOTALL
        )
        if audio_match:
            audio_text = audio_match.group(1).strip()

        # [EFFECT]: íŒŒì‹± (íš¨ê³¼ìŒ íƒ€ì…)
        effect_match = re.search(r'\[EFFECT\]:\s*(\w+)', content)
        if effect_match:
            effect_type = effect_match.group(1).strip()

        return speakers, audio_text, effect_type

    def parse_dialogue_lines(self, audio_text: str) -> List[Dict]:
        """
        ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ ê°œë³„ ë°œí™”ë¡œ ë¶„ë¦¬

        Example input:
            Emma: Hi, are you coming to the party?
            John: Yes, I'll be there at 7 PM.

        Returns:
            [{'speaker': 'Emma', 'text': 'Hi, are you coming to the party?'}, ...]
        """
        lines = []
        for line in audio_text.split('\n'):
            line = line.strip()
            if not line:
                continue

            # "Speaker: text" í˜•ì‹ íŒŒì‹±
            match = re.match(r'^([A-Za-z\s]+):\s*(.+)$', line)
            if match:
                speaker = match.group(1).strip()
                text = match.group(2).strip()
                lines.append({'speaker': speaker, 'text': text})

        return lines

    def get_openai_voice(self, speaker_name: str, speakers: List[Dict]) -> str:
        """
        í™”ìì˜ OpenAI TTS ìŒì„± ê²°ì •

        Args:
            speaker_name: í™”ì ì´ë¦„ (ì˜ˆ: 'Emma')
            speakers: [SPEAKERS] ì •ë³´

        Returns:
            OpenAI voice name (nova, onyx, etc.)
        """
        # speakersì—ì„œ í•´ë‹¹ í™”ì ì°¾ê¸°
        speaker_info = next((s for s in speakers if s['name'] == speaker_name), None)

        if speaker_info and 'voice' in speaker_info:
            # ë§¤í•‘ëœ ìŒì„± ì‚¬ìš©
            original_voice = speaker_info['voice']
            openai_voice = self.voice_map.get(original_voice, 'alloy')
            return openai_voice

        # ê¸°ë³¸ê°’: ì„±ë³„ë¡œ ê²°ì •
        if speaker_info and speaker_info.get('gender') == 'male':
            return 'onyx'
        else:
            return 'nova'

    def generate_tts_segment(self, text: str, voice: str, speed: float = 1.0) -> bytes:
        """
        OpenAI TTSë¡œ ìŒì„± ìƒì„±

        Args:
            text: ë°œí™” í…ìŠ¤íŠ¸
            voice: OpenAI voice (nova, onyx, etc.)
            speed: ì†ë„ (0.25 ~ 4.0)

        Returns:
            MP3 audio bytes
        """
        try:
            print(f"ğŸ¤ Generating TTS: voice={voice}, text='{text[:50]}...'")

            response = self.client.audio.speech.create(
                model="tts-1",
                voice=voice,
                input=text,
                speed=speed
            )

            # Return audio bytes directly
            return response.content

        except Exception as e:
            print(f"âŒ TTS generation failed: {e}")
            return b''  # Empty bytes on error

    def create_listening_audio(
        self,
        content: str,
        speed: float = 0.9
    ) -> Optional[str]:
        """
        ë“£ê¸° ë¬¸ì œ ì „ì²´ ì˜¤ë””ì˜¤ ìƒì„± (í™”ìë³„ ìŒì„± + íš¨ê³¼ìŒ ë¯¹ì‹±)

        Args:
            content: ë¬¸ì œ ì „ì²´ í…ìŠ¤íŠ¸ ([SPEAKERS], [AUDIO] í¬í•¨)
            speed: TTS ì†ë„ (0.9 = ì¡°ê¸ˆ ëŠë¦¬ê²Œ, ë“£ê¸°ì— ì í•©)

        Returns:
            ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: '/static/audio/problem_abc123.mp3')
            ì‹¤íŒ¨ ì‹œ None
        """
        # 1. íŒŒì‹±
        speakers, audio_text, effect_type = self.parse_listening_problem(content)

        if not audio_text:
            print("âš ï¸ No [AUDIO] content found")
            return None

        if not speakers:
            print("âš ï¸ No [SPEAKERS] info found")
            return None

        dialogue_lines = self.parse_dialogue_lines(audio_text)

        if not dialogue_lines:
            print("âš ï¸ No dialogue lines parsed")
            return None

        print(f"ğŸ“ Generating TTS for {len(dialogue_lines)} lines from {len(speakers)} speakers")

        # Check if pydub is available for multi-speaker support
        if not PYDUB_AVAILABLE:
            print("âš ï¸ pydub not available - using single voice fallback")
            # Fallback to simple version
            voice = 'alloy'
            if speakers and len(speakers) > 0:
                speaker_voice = speakers[0].get('voice', 'Samantha')
                voice = self.voice_map.get(speaker_voice, 'alloy')

            audio_bytes = self.generate_tts_segment(audio_text, voice, speed)
            if not audio_bytes:
                return None

            content_hash = hashlib.md5(content.encode()).hexdigest()[:12]
            filename = f"listening_{content_hash}.mp3"
            output_path = self.audio_dir / filename

            with open(output_path, 'wb') as f:
                f.write(audio_bytes)
            print(f"âœ… Audio saved (single voice): {output_path}")
            return f"/static/audio/{filename}"

        # 2. ê° ë°œí™”ë¥¼ ê°œë³„ TTSë¡œ ìƒì„± (í™”ìë³„ ë‹¤ë¥¸ ìŒì„±)
        combined_audio = AudioSegment.silent(duration=500)  # 0.5ì´ˆ ë¬´ìŒìœ¼ë¡œ ì‹œì‘

        for i, line in enumerate(dialogue_lines):
            speaker_name = line['speaker']
            text = line['text']

            # ìŒì„± ì„ íƒ (í™”ìë³„)
            voice = self.get_openai_voice(speaker_name, speakers)

            print(f"  [{i+1}/{len(dialogue_lines)}] {speaker_name}: {text[:30]}... (voice={voice})")

            # TTS ìƒì„±
            audio_bytes = self.generate_tts_segment(text, voice, speed)

            if not audio_bytes:
                print(f"    âš ï¸ TTS failed for line {i+1}, skipping")
                continue

            # bytesë¥¼ AudioSegmentë¡œ ë³€í™˜
            try:
                from io import BytesIO
                segment = AudioSegment.from_mp3(BytesIO(audio_bytes))

                # ê²°í•© (ë°œí™” ì‚¬ì´ 0.3ì´ˆ ê°„ê²©)
                combined_audio += segment
                combined_audio += AudioSegment.silent(duration=300)

            except Exception as e:
                print(f"    âš ï¸ Failed to convert audio segment: {e}")
                continue

        # 3. íš¨ê³¼ìŒ ì¶”ê°€ (ìˆìœ¼ë©´)
        if effect_type and effect_type in self.effects:
            effect_file = self.effects_dir / self.effects[effect_type]
            if effect_file.exists():
                try:
                    effect = AudioSegment.from_mp3(str(effect_file))
                    # íš¨ê³¼ìŒì„ ë°°ê²½ì— ê¹”ê¸° (ë³¼ë¥¨ -20dB)
                    effect = effect - 20
                    # íš¨ê³¼ìŒ ê¸¸ì´ë¥¼ ëŒ€í™” ê¸¸ì´ì— ë§ì¶¤
                    if len(effect) < len(combined_audio):
                        effect = effect * (len(combined_audio) // len(effect) + 1)
                    effect = effect[:len(combined_audio)]

                    combined_audio = combined_audio.overlay(effect)
                    print(f"âœ… Added sound effect: {effect_type}")
                except Exception as e:
                    print(f"âš ï¸ Failed to add effect: {e}")

        # 4. íŒŒì¼ ì €ì¥ (í•´ì‹œ ê¸°ë°˜ íŒŒì¼ëª…)
        content_hash = hashlib.md5(content.encode()).hexdigest()[:12]
        filename = f"listening_{content_hash}.mp3"
        output_path = self.audio_dir / filename

        try:
            combined_audio.export(str(output_path), format="mp3", bitrate="128k")
            print(f"âœ… Audio saved: {output_path} ({len(combined_audio)}ms, {len(dialogue_lines)} segments)")

            # ì›¹ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œ ë°˜í™˜
            return f"/static/audio/{filename}"

        except Exception as e:
            print(f"âŒ Failed to save audio: {e}")
            return None

    def get_or_create_audio(self, content: str, force_regenerate: bool = False) -> Optional[str]:
        """
        ìºì‹œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ ìƒì„±

        Args:
            content: ë¬¸ì œ ë‚´ìš©
            force_regenerate: Trueë©´ ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œí•˜ê³  ì¬ìƒì„±

        Returns:
            ì˜¤ë””ì˜¤ íŒŒì¼ URL
        """
        content_hash = hashlib.md5(content.encode()).hexdigest()[:12]
        filename = f"listening_{content_hash}.mp3"
        file_path = self.audio_dir / filename

        # ìºì‹œ í™•ì¸
        if not force_regenerate and file_path.exists():
            print(f"âœ… Using cached audio: {filename}")
            return f"/static/audio/{filename}"

        # ìƒˆë¡œ ìƒì„±
        return self.create_listening_audio(content)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_tts_service = None

def get_tts_service() -> TTSService:
    """TTS ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ getter"""
    global _tts_service
    if _tts_service is None:
        _tts_service = TTSService()
    return _tts_service
