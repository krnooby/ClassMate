# -*- coding: utf-8 -*-
"""
Student Agent Service
OpenAI Function Calling ê¸°ë°˜ í•™ìƒ ìƒë‹´ ì‹œìŠ¤í…œ
"""
from __future__ import annotations
import os
import json
from typing import List, Dict, Any, Optional
from openai import OpenAI
from shared.services import get_graph_rag_service
from shared.prompts import PromptManager
from shared.services.tts_service import get_tts_service


class StudentAgentService:
    """í•™ìƒ ë§ì¶¤ Function Calling ì—ì´ì „íŠ¸"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.openai_api_key)
        self.graph_rag_service = get_graph_rag_service()

        # Current user message for vector search context
        self.current_user_message = ""

        # Function definitions
        self.functions = self._create_functions()

    def _create_functions(self) -> List[Dict[str, Any]]:
        """OpenAI Function Callingìš© function ì •ì˜"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "get_student_context",
                    "description": "í•™ìƒì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì´ë¦„, í•™ë…„, CEFR ë ˆë²¨, ê°•ì , ì•½ì , ì˜ì—­ë³„ ì ìˆ˜, ì¶œì„ë¥ , ìˆ™ì œ ì™„ë£Œìœ¨, ë°˜ ì •ë³´, ì‹œê°„í‘œ ë“±)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "student_id": {
                                "type": "string",
                                "description": "í•™ìƒ ID (ì˜ˆ: S-01)"
                            }
                        },
                        "required": ["student_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "recommend_problems",
                    "description": "DBì—ì„œ í•™ìƒì˜ ì•½ì ì— ë§ëŠ” ì˜ì–´ ë¬¸ì œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "student_id": {
                                "type": "string",
                                "description": "í•™ìƒ ID"
                            },
                            "area": {
                                "type": "string",
                                "description": "ë¬¸ì œ ì˜ì—­ (ë…í•´, ë¬¸ë²•, ì–´íœ˜, ë“£ê¸°, ì“°ê¸° ì¤‘ í•˜ë‚˜, ë˜ëŠ” nullì¼ ê²½ìš° ì•½ì  ìë™ ê°ì§€)",
                                "enum": ["ë…í•´", "ë¬¸ë²•", "ì–´íœ˜", "ë“£ê¸°", "ì“°ê¸°", None]
                            },
                            "limit": {
                                "type": "integer",
                                "description": "ë¬¸ì œ ê°œìˆ˜ (ê¸°ë³¸ê°’ 3)",
                                "default": 3
                            }
                        },
                        "required": ["student_id"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "generate_problem",
                    "description": "AIê°€ ìƒˆë¡œìš´ ì˜ì–´ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ê³ í’ˆì§ˆ). ë“£ê¸° ë¬¸ì œëŠ” ìë™ìœ¼ë¡œ ëŒ€í™” ìŒì„±ê³¼ [AUDIO], [SPEAKERS] íƒœê·¸ê°€ í¬í•¨ë©ë‹ˆë‹¤. difficultyë¥¼ ìƒëµí•˜ë©´ í•™ìƒì˜ CEFR ë ˆë²¨ì— ë§ì¶° ìë™ ìƒì„±ë©ë‹ˆë‹¤.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "student_id": {
                                "type": "string",
                                "description": "í•™ìƒ ID (CEFR ë ˆë²¨ ìë™ ì¡°íšŒìš©)"
                            },
                            "area": {
                                "type": "string",
                                "description": "ë¬¸ì œ ì˜ì—­: 'ë“£ê¸°' (listening), 'ë…í•´' (reading), 'ë¬¸ë²•' (grammar), 'ì–´íœ˜' (vocabulary), 'ì“°ê¸°' (writing)"
                            },
                            "difficulty": {
                                "type": "string",
                                "description": "ë‚œì´ë„ CEFR ë ˆë²¨ (A1, A2, B1, B2, C1, C2). ìƒëµ ì‹œ í•™ìƒì˜ í˜„ì¬ ë ˆë²¨ ì‚¬ìš©"
                            },
                            "topic": {
                                "type": "string",
                                "description": "ì£¼ì œ - ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì£¼ì œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ˆ: ì—¬í–‰, ì‡¼í•‘, ë ˆìŠ¤í† ë‘ ì˜ˆì•½, ë³‘ì› ì˜ˆì•½, ë„ì„œê´€, ì˜í™”ê´€, ìš´ë™, ì·¨ë¯¸, í•™êµ ìƒí™œ, ì¹œêµ¬ ëª¨ì„, ê°€ì¡± í–‰ì‚¬, íœ´ê°€ ê³„íš, ë´‰ì‚¬í™œë™ ë“±. ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ë‹¤ì–‘í•œ ì£¼ì œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”."
                            },
                            "num_speakers": {
                                "type": "integer",
                                "description": "ë“£ê¸° ë¬¸ì œì˜ í™”ì ìˆ˜ (2, 3, 4 ë“±). ì‚¬ìš©ìê°€ '3ëª…', 'ì—¬ëŸ¬ ëª…', 'ì„¸ ëª…' ë“±ì„ ì–¸ê¸‰í•˜ë©´ í•´ë‹¹ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ê¸°ë³¸ê°’ì€ 2ëª…ì…ë‹ˆë‹¤."
                            }
                        },
                        "required": ["student_id", "area"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "evaluate_writing",
                    "description": "ì“°ê¸°(ì„œìˆ í˜•) ë‹µì•ˆì„ AIê°€ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤ (ë¬¸ë²•, ì–´íœ˜, êµ¬ì¡°, ë‚´ìš©)",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "prompt": {
                                "type": "string",
                                "description": "ì“°ê¸° ë¬¸ì œ í”„ë¡¬í”„íŠ¸ (ì£¼ì œ/ì§ˆë¬¸)"
                            },
                            "student_answer": {
                                "type": "string",
                                "description": "í•™ìƒì´ ì‘ì„±í•œ ì˜ì–´ ë‹µì•ˆ"
                            },
                            "difficulty": {
                                "type": "string",
                                "description": "ë‚œì´ë„ CEFR ë ˆë²¨ (A1, A2, B1, B2, C1, C2)"
                            }
                        },
                        "required": ["prompt", "student_answer", "difficulty"]
                    }
                }
            }
        ]

    def _get_student_context(self, student_id: str, query_text: str = "í•™ìƒ ì •ë³´ ì¡°íšŒ") -> str:
        """í•™ìƒ ì •ë³´ ì¡°íšŒ ì‹¤í–‰ (ë²¡í„° ê²€ìƒ‰ í¬í•¨)"""
        try:
            context = self.graph_rag_service.get_rag_context(
                student_id=student_id,
                query_text=query_text,
                use_vector_search=True
            )
            return context
        except Exception as e:
            return f"í•™ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

    def _recommend_problems(self, student_id: str, area: Optional[str] = None, limit: int = 3) -> str:
        """ë¬¸ì œ ì¶”ì²œ ì‹¤í–‰"""
        try:
            # Writing(ì„œìˆ í˜•)ì€ DBì—ì„œ ì¶”ì²œí•˜ì§€ ì•ŠìŒ - í•­ìƒ generate_problem ì‚¬ìš©
            if area and area.upper() in ['WR', 'WRITING', 'ì“°ê¸°']:
                return "ì“°ê¸°(Writing) ë¬¸ì œëŠ” DB ì¶”ì²œì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. generate_problem functionì„ ì‚¬ìš©í•˜ì—¬ ììœ  ì„œìˆ í˜• ë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."

            problems = self.graph_rag_service.search_problems_for_student(
                student_id=student_id,
                area=area,
                limit=limit
            )

            if not problems:
                return "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë¬¸ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # ë¬¸ì œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            result = []
            area_names = {
                'RD': 'Reading', 'GR': 'Grammar', 'WR': 'Writing',
                'LS': 'Listening', 'VO': 'Vocabulary'
            }

            for i, p in enumerate(problems, 1):
                area_en = area_names.get(p['area'], p['area'])
                problem_text = f"Problem {i} [{area_en}]:\n"

                # Listening ë¬¸ì œëŠ” audio_transcript í¬í•¨
                if p.get('audio_transcript'):
                    problem_text += f"[AUDIO]: {p['audio_transcript']}\n"

                problem_text += f"{p['stem']}\n"
                if p['options']:
                    for j, opt in enumerate(p['options'], 1):
                        problem_text += f"   {j}) {opt}\n"
                problem_text += f"Answer: {p['answer']}\n"
                result.append(problem_text)

            return "\n".join(result)
        except Exception as e:
            return f"ë¬¸ì œ ì¶”ì²œ ì‹¤íŒ¨: {str(e)}"

    def _generate_problem(self, student_id: str, area: str, difficulty: str = None, topic: str = None, num_speakers: int = 2) -> str:
        """AI ë¬¸ì œ ìƒì„± ì‹¤í–‰ (o4-mini - ë¹ ë¥¸ ì¶”ë¡  ëª¨ë¸)"""
        try:
            # topicì´ ì—†ìœ¼ë©´ ë‹¤ì–‘í•œ ì£¼ì œ ì¤‘ ëœë¤ ì„ íƒ
            if not topic:
                import random
                topics = [
                    "ë ˆìŠ¤í† ë‘ ì˜ˆì•½", "ì˜í™”ê´€ ë°©ë¬¸", "ë„ì„œê´€ ì´ìš©", "ì‡¼í•‘", "ë³‘ì› ì˜ˆì•½",
                    "ì—¬í–‰ ê³„íš", "ìš´ë™", "ì·¨ë¯¸ í™œë™", "í•™êµ ìƒí™œ", "ì¹œêµ¬ ëª¨ì„",
                    "ê°€ì¡± í–‰ì‚¬", "íœ´ê°€ ê³„íš", "ë´‰ì‚¬í™œë™", "ë™ì•„ë¦¬ í™œë™", "íŒŒí‹° ì¤€ë¹„"
                ]
                topic = random.choice(topics)
                print(f"ğŸ“Œ ìë™ ì„ íƒëœ ì£¼ì œ: {topic}")

            # difficultyê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í•™ìƒì˜ CEFR ë ˆë²¨ ì¡°íšŒ
            if not difficulty:
                try:
                    # GraphRAG ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í•™ìƒ ì •ë³´ ì¡°íšŒ
                    student_context = self.graph_rag_service.get_rag_context(
                        student_id=student_id,
                        query_text="í•™ìƒì˜ CEFR ë ˆë²¨ ì•Œë ¤ì¤˜",
                        use_vector_search=False  # ì§ì ‘ ê·¸ë˜í”„ ì¡°íšŒ
                    )

                    # CEFR ë ˆë²¨ ì¶”ì¶œ (A1, A2, B1, B2, C1, C2 ì¤‘ í•˜ë‚˜)
                    import re
                    cefr_match = re.search(r'\b(A1|A2|B1|B2|C1|C2)\b', student_context, re.IGNORECASE)
                    if cefr_match:
                        difficulty = cefr_match.group(1).upper()
                        print(f"ğŸ“Š í•™ìƒ {student_id}ì˜ CEFR ë ˆë²¨: {difficulty}")
                    else:
                        # ê¸°ë³¸ê°’: B1
                        difficulty = "B1"
                        print(f"âš ï¸  í•™ìƒ {student_id}ì˜ CEFR ë ˆë²¨ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ B1 ì‚¬ìš©")
                except Exception as e:
                    print(f"âš ï¸  CEFR ë ˆë²¨ ì¡°íšŒ ì‹¤íŒ¨: {e}, ê¸°ë³¸ê°’ B1 ì‚¬ìš©")
                    difficulty = "B1"

            # PromptManagerë¥¼ ì‚¬ìš©í•´ ë¬¸ì œ ìƒì„± í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            prompt = PromptManager.get_problem_generation_prompt(
                area=area,
                difficulty=difficulty,
                topic=topic,
                num_speakers=num_speakers,
                model="o4-mini"
            )

            is_listening = area.lower() in ['ë“£ê¸°', 'listening', 'ls']
            print(f"ğŸ¯ ë¬¸ì œ ìƒì„±: area={area}, difficulty={difficulty}, topic={topic}, num_speakers={num_speakers}, is_listening={is_listening}")

            # ë“£ê¸° ë¬¸ì œëŠ” ìµœëŒ€ 2íšŒ ì¬ì‹œë„
            max_attempts = 2 if is_listening else 1

            for attempt in range(max_attempts):
                try:
                    # o4-mini - o3-mini í›„ì†, ë¹ ë¥¸ ì†ë„ + ìš°ìˆ˜í•œ STEM ì„±ëŠ¥
                    # NOTE: o4-mini uses reasoning tokens + output tokens, so we need more tokens for listening problems
                    max_tokens = 10000 if is_listening else 3000
                    response = self.client.chat.completions.create(
                        model="o4-mini",
                        messages=[{"role": "user", "content": prompt}],
                        max_completion_tokens=max_tokens
                    )

                    content = response.choices[0].message.content

                    if is_listening and content:
                        print(f"âœ… o4-mini ë“£ê¸° ë¬¸ì œ ìƒì„± ì™„ë£Œ: {len(content)} ê¸€ì")

                    # ë“£ê¸° ë¬¸ì œ í›„ì²˜ë¦¬
                    if is_listening:
                        content = self._postprocess_listening_problem(content, attempt + 1)

                    return content

                except Exception as retry_error:
                    if attempt == max_attempts - 1:
                        raise retry_error
                    print(f"âš ï¸  ë“£ê¸° ë¬¸ì œ ìƒì„± ì¬ì‹œë„ ({attempt + 1}/{max_attempts})")
                    continue

        except Exception as e:
            # Fallback to GPT-4o (ë¹ ë¥´ê³  ì•ˆì •ì )
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "You are an expert English language teacher creating high-quality assessment questions."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.8,
                    max_tokens=1500
                )

                content = response.choices[0].message.content

                # ë“£ê¸° ë¬¸ì œ í›„ì²˜ë¦¬
                if is_listening:
                    content = self._postprocess_listening_problem(content, attempt=1)

                return content

            except Exception as fallback_error:
                return f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}, Fallback ì‹¤íŒ¨: {str(fallback_error)}"

    def _postprocess_listening_problem(self, content: str, attempt: int) -> str:
        """
        ë“£ê¸° ë¬¸ì œ í›„ì²˜ë¦¬ (ê°•ì œ ê²€ì¦ ë° ìˆ˜ì •)

        1. [AUDIO]: íŒ¨í„´ í™•ì¸ ë° ì¶”ê°€
        2. [SPEAKERS]: JSON íŒŒì‹± ë° ìë™ ìƒì„±
        3. ëŒ€í™” í˜•ì‹ ê²€ì¦
        4. ì²« ë°œí™”ì— í™”ì ì´ë¦„ ì¶”ê°€
        """
        import re
        import json

        lines = content.split('\n')

        # 1. [AUDIO]: íŒ¨í„´ í™•ì¸
        has_audio_tag = any('[AUDIO]:' in line for line in lines)

        # 2. [SPEAKERS]: JSON íŒŒì‹±
        speakers_match = re.search(r'\[SPEAKERS\]:\s*({.*})', content)
        has_speakers_tag = speakers_match is not None

        # Check if voice field exists in existing SPEAKERS JSON
        needs_voice_enhancement = False
        if has_speakers_tag:
            try:
                existing_speakers = json.loads(speakers_match.group(1))
                speakers_list = existing_speakers.get('speakers', [])
                # Check if ANY speaker is missing voice field
                if speakers_list and not all('voice' in s for s in speakers_list):
                    needs_voice_enhancement = True
                    print(f"   âš ï¸  [SPEAKERS]: voice í•„ë“œ ì—†ìŒ â†’ o4-minië¡œ ì¶”ê°€ ì˜ˆì •")
            except:
                pass

        # 3. ëŒ€í™” í˜•ì‹ í™•ì¸ (Name: text íŒ¨í„´)
        dialogue_pattern = re.compile(r'^([A-Z][a-z]+):\s+.+', re.MULTILINE)
        dialogue_matches = dialogue_pattern.findall(content)

        # ì²« ë²ˆì§¸ ëŒ€í™” ì°¾ê¸° (í™”ì ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°ë„ í¬í•¨)
        # ì˜ˆ: "Hi Jake, have you done..." ê°™ì€ ê²½ìš°
        first_utterance_pattern = re.compile(r'^[A-Z][^:]{10,}', re.MULTILINE)
        first_utterance_matches = first_utterance_pattern.findall(content)

        has_dialogue = len(dialogue_matches) >= 1 or len(first_utterance_matches) >= 1

        print(f"ğŸ” ë“£ê¸° ë¬¸ì œ ê²€ì¦ (ì‹œë„ {attempt}):")
        print(f"   - [AUDIO]: {has_audio_tag}")
        print(f"   - [SPEAKERS]: {has_speakers_tag}")
        print(f"   - ëŒ€í™” í˜•ì‹ (Name:): {len(dialogue_matches)}ê°œ")
        print(f"   - ì²« ë°œí™” (í™”ì ì—†ìŒ): {len(first_utterance_matches)}ê°œ")

        # ëŒ€í™” í˜•ì‹ì´ ì—†ìœ¼ë©´ ë…ë°±í˜•ìœ¼ë¡œ ê°„ì£¼ (í™”ì ë¶„ë¦¬ ì—†ìŒ)
        if not has_dialogue:
            print(f"   â„¹ï¸  ë…ë°±í˜• ë“£ê¸° ë¬¸ì œ (í™”ì ë¶„ë¦¬ ì—†ìŒ)")
            print(f"   âœ… ë“£ê¸° ë¬¸ì œ ê²€ì¦ í†µê³¼ (ë…ë°±í˜•)!")
            return '\n'.join(lines)  # í›„ì²˜ë¦¬ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜

        # [AUDIO]: íƒœê·¸ ê°•ì œ ì¶”ê°€
        if not has_audio_tag:
            print(f"   âš ï¸  [AUDIO]: íƒœê·¸ ì—†ìŒ â†’ ê°•ì œ ì¶”ê°€")
            # Find first dialogue line or first utterance
            first_dialogue_idx = None
            for i, line in enumerate(lines):
                if dialogue_pattern.match(line.strip()) or first_utterance_pattern.match(line.strip()):
                    first_dialogue_idx = i
                    break

            if first_dialogue_idx is not None:
                lines.insert(first_dialogue_idx, '[AUDIO]:')

        # [SPEAKERS]: JSON ìë™ ìƒì„± ë˜ëŠ” voice enhancement
        if (not has_speakers_tag or needs_voice_enhancement) and has_dialogue:
            if not has_speakers_tag:
                print(f"   âš ï¸  [SPEAKERS]: íƒœê·¸ ì—†ìŒ â†’ ìë™ ìƒì„±")
            else:
                print(f"   âš ï¸  [SPEAKERS]: voice í•„ë“œ ì¶”ê°€ ì¤‘...")

            # Extract unique speaker names from existing labels
            unique_speakers = []
            seen = set()
            for match in dialogue_matches:
                if match not in seen:
                    unique_speakers.append(match)
                    seen.add(match)

            # If only 1 speaker found but we need 2, add a default second speaker
            if len(unique_speakers) == 1:
                # Infer second speaker from context
                first_name = unique_speakers[0]
                # Default second names
                if first_name.lower() in ['emma', 'sarah', 'lisa', 'maria', 'anna']:
                    second_name = 'Jake'  # Male counterpart
                else:
                    second_name = 'Emma'  # Female counterpart
                unique_speakers.insert(0, second_name)  # Add as first speaker
                print(f"   â„¹ï¸  í™”ì 1ëª…ë§Œ ê°ì§€ â†’ ë‘ ë²ˆì§¸ í™”ì ì¶”ê°€: {second_name}")

            # Use LLM to determine gender and voice for each speaker
            # Build a prompt for the LLM
            speaker_names = ", ".join(unique_speakers)
            llm_prompt = f"""Given these speaker names: {speaker_names}

For EACH speaker, determine:
1. Gender (male or female)
2. US English voice name - IMPORTANT: Assign DIFFERENT voices to DIFFERENT speakers!

Available voices:
- Female voices: Samantha, Karen, Victoria
- Male voices: David, Daniel, Mark

CRITICAL RULES:
- If you have 2 speakers, they MUST use DIFFERENT voice names
- Never assign the same voice to multiple speakers in one conversation
- Example (CORRECT): Speaker1 uses Samantha, Speaker2 uses David
- Example (WRONG): Speaker1 uses Samantha, Speaker2 uses Samantha

Respond with ONLY valid JSON:
{{
  "speakers": [
    {{"name": "Name1", "gender": "female", "voice": "Samantha"}},
    {{"name": "Name2", "gender": "male", "voice": "David"}}
  ]
}}"""

            try:
                # Call LLM to determine speakers (o4-mini - ì¶”ë¡  ëª¨ë¸)
                llm_response = self.client.chat.completions.create(
                    model="o4-mini",  # Reasoning model for speaker analysis
                    messages=[{"role": "user", "content": llm_prompt}],
                    max_completion_tokens=300
                )

                # o4-mini doesn't support JSON mode, parse from text
                content = llm_response.choices[0].message.content
                # Extract JSON from response (handle markdown code blocks)
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    speakers_json = json.loads(json_match.group(0))
                else:
                    speakers_json = json.loads(content)

                print(f"   âœ… o4-miniê°€ í™”ì ì •ë³´ ìƒì„±: {speakers_json}")

            except Exception as e:
                print(f"   âš ï¸  LLM í˜¸ì¶œ ì‹¤íŒ¨, fallback to rules: {e}")
                # Fallback to rule-based
                female_names = {'sarah', 'emma', 'lisa', 'maria', 'anna', 'kate', 'jane', 'mary', 'lucy', 'emily'}
                male_names = {'tom', 'john', 'mike', 'david', 'james', 'robert', 'mark', 'peter', 'kevin', 'alex', 'jake'}

                speakers_json = {"speakers": []}
                for name in unique_speakers:
                    name_lower = name.lower()
                    if name_lower in female_names:
                        gender = "female"
                        voice = "Samantha"
                    elif name_lower in male_names:
                        gender = "male"
                        voice = "David"
                    else:
                        # Default: alternate male/female
                        gender = "female" if len(speakers_json["speakers"]) % 2 == 0 else "male"
                        voice = "Samantha" if gender == "female" else "David"

                    speakers_json["speakers"].append({"name": name, "gender": gender, "voice": voice})

            # Insert or Replace [SPEAKERS]: line
            speakers_line = f"[SPEAKERS]: {json.dumps(speakers_json)}"

            if needs_voice_enhancement:
                # Replace existing [SPEAKERS]: line
                for i, line in enumerate(lines):
                    if '[SPEAKERS]:' in line:
                        lines[i] = speakers_line
                        print(f"   âœ… [SPEAKERS]: voice í•„ë“œ ì¶”ê°€ ì™„ë£Œ ({len(speakers_json['speakers'])}ëª…)")
                        break
            else:
                # Insert new [SPEAKERS]: line after [AUDIO]:
                audio_idx = None
                for i, line in enumerate(lines):
                    if '[AUDIO]:' in line:
                        audio_idx = i
                        break

                if audio_idx is not None:
                    lines.insert(audio_idx + 1, speakers_line)
                    print(f"   âœ… [SPEAKERS]: ìë™ ìƒì„± ì™„ë£Œ ({len(speakers_json['speakers'])}ëª…)")

        # 4. ì²« ë°œí™”ì— í™”ì ì´ë¦„ ì¶”ê°€ (ì—†ëŠ” ê²½ìš°)
        # Re-parse speakers JSON to get first speaker
        speakers_match = re.search(r'\[SPEAKERS\]:\s*({.*})', '\n'.join(lines))
        if speakers_match:
            try:
                speakers_data = json.loads(speakers_match.group(1))
                speakers_list = speakers_data.get('speakers', [])

                if speakers_list:
                    first_speaker = speakers_list[0]['name']

                    # Find first line after [SPEAKERS]: that looks like dialogue but has no speaker label
                    speakers_idx = None
                    for i, line in enumerate(lines):
                        if '[SPEAKERS]:' in line:
                            speakers_idx = i
                            break

                    if speakers_idx is not None:
                        # Check next few lines for dialogue without speaker
                        for i in range(speakers_idx + 1, min(speakers_idx + 5, len(lines))):
                            line = lines[i].strip()
                            # Skip empty lines and lines that already have speaker labels
                            if not line or dialogue_pattern.match(line):
                                continue
                            # If it's a sentence (starts with capital, has words)
                            if re.match(r'^[A-Z][^:]{10,}', line):
                                # Add first speaker name
                                lines[i] = f"{first_speaker}: {line}"
                                print(f"   âœ… ì²« ë°œí™”ì— í™”ì ì¶”ê°€: {first_speaker}:")
                                break
            except Exception as e:
                print(f"   âš ï¸  ì²« ë°œí™” í™”ì ì¶”ê°€ ì‹¤íŒ¨: {e}")

        result = '\n'.join(lines)

        # Final verification
        final_has_audio = '[AUDIO]:' in result
        final_has_speakers = '[SPEAKERS]:' in result
        final_dialogue_count = len(re.findall(r'^([A-Z][a-z]+):\s+', result, re.MULTILINE))

        print(f"   ğŸ“Š ìµœì¢… ëŒ€í™” ìˆ˜: {final_dialogue_count}ê°œ")

        if final_has_audio and final_has_speakers and final_dialogue_count >= 2:
            print(f"   âœ… ë“£ê¸° ë¬¸ì œ ê²€ì¦ í†µê³¼!")
        else:
            print(f"   âš ï¸  ìµœì¢… ê²€ì¦ - AUDIO: {final_has_audio}, SPEAKERS: {final_has_speakers}, ëŒ€í™”: {final_dialogue_count}ê°œ")

        # ğŸ™ï¸ OpenAI TTSë¡œ ê³ í’ˆì§ˆ ìŒì„± ìƒì„±
        if final_has_audio and final_has_speakers:
            try:
                print(f"   ğŸ™ï¸  OpenAI TTS ìŒì„± ìƒì„± ì¤‘...")
                tts_service = get_tts_service()
                audio_url = tts_service.get_or_create_audio(result)

                if audio_url:
                    # Add audio URL to the beginning of the problem (for frontend to use)
                    result = f"[AUDIO_URL]: {audio_url}\n\n{result}"
                    print(f"   âœ… TTS ìŒì„± ìƒì„± ì™„ë£Œ: {audio_url}")
                else:
                    print(f"   âš ï¸  TTS ìŒì„± ìƒì„± ì‹¤íŒ¨ - ë¸Œë¼ìš°ì € TTS ì‚¬ìš©")
            except Exception as e:
                print(f"   âš ï¸  TTS ì˜¤ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
                print(f"   â„¹ï¸  ë¸Œë¼ìš°ì € TTS fallback ì‚¬ìš©")

        return result

    def _evaluate_writing(self, prompt: str, student_answer: str, difficulty: str) -> str:
        """
        ì„œìˆ í˜• ì“°ê¸° ë‹µì•ˆ í‰ê°€ (o4-mini ì¶”ë¡  ëª¨ë¸)

        í‰ê°€ ê¸°ì¤€:
        - Grammar (ë¬¸ë²•): 15ì 
        - Vocabulary (ì–´íœ˜): 15ì 
        - Organization (êµ¬ì¡°): 20ì 
        - Content (ë‚´ìš©): 30ì 
        - Fluency (ìœ ì°½ì„±): 20ì 
        ì´ 100ì 
        """
        try:
            evaluation_prompt = f"""You are an expert English writing evaluator for CEFR {difficulty} level students.

**Writing Prompt:**
{prompt}

**Student's Answer:**
{student_answer}

**Evaluation Task:**
Evaluate this student's writing comprehensively using the following criteria:

1. **Grammar (15 points)**: Accuracy of grammar, sentence structure, verb tenses
2. **Vocabulary (15 points)**: Range and appropriateness of vocabulary for {difficulty} level
3. **Organization (20 points)**: Logical flow, paragraph structure, coherence
4. **Content (30 points)**: Relevance to prompt, depth of ideas, completeness
5. **Fluency (20 points)**: Natural expression, readability, overall language flow

**Output Format (IMPORTANT):**
Provide your evaluation in the following structured format:

**Overall Score:** [X/100]

**Grammar (X/15):**
- Strengths: [brief]
- Weaknesses: [brief]

**Vocabulary (X/15):**
- Strengths: [brief]
- Weaknesses: [brief]

**Organization (X/20):**
- Strengths: [brief]
- Weaknesses: [brief]

**Content (X/30):**
- Strengths: [brief]
- Weaknesses: [brief]

**Fluency (X/20):**
- Strengths: [brief]
- Weaknesses: [brief]

**Key Recommendations:**
1. [First improvement suggestion]
2. [Second improvement suggestion]
3. [Third improvement suggestion]

**Corrected Version (if needed):**
[Provide a corrected/improved version of the student's writing, maintaining their ideas but fixing errors]
"""

            # o4-minië¡œ ì¶”ë¡  ê¸°ë°˜ í‰ê°€
            response = self.client.chat.completions.create(
                model="o4-mini",
                messages=[{"role": "user", "content": evaluation_prompt}],
                max_completion_tokens=2500
            )

            return response.choices[0].message.content

        except Exception as e:
            # Fallback to GPT-4o
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "You are an expert English writing evaluator."},
                        {"role": "user", "content": evaluation_prompt}
                    ],
                    temperature=0.3,  # Lower temperature for consistent evaluation
                    max_tokens=2000
                )
                return response.choices[0].message.content
            except Exception as fallback_error:
                return f"í‰ê°€ ì‹¤íŒ¨: {str(e)}, Fallback ì‹¤íŒ¨: {str(fallback_error)}"

    def _parse_quick_reply(self, content: str, used_models: List[str]) -> Dict[str, Any]:
        """
        ì‘ë‹µì—ì„œ [QUICK_REPLY:...] íŒ¨í„´ì„ íŒŒì‹±í•˜ì—¬ quick_replies í•„ë“œë¡œ ë³€í™˜

        Format: [QUICK_REPLY:VO|RD|WR|LS|GR]
        ê° ì½”ë“œëŠ” í´ë¦­ ê°€ëŠ¥í•œ ë²„íŠ¼ìœ¼ë¡œ ë³€í™˜ë¨
        """
        import re

        # Quick reply íŒ¨í„´ ê²€ìƒ‰
        pattern = r'\[QUICK_REPLY:(.*?)\]'
        match = re.search(pattern, content)

        if match:
            # Quick reply ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: "VO|RD|WR|LS|GR")
            codes = match.group(1).split('|')

            # ì½”ë“œë¥¼ í•œê¸€ ì´ë¦„ê³¼ ë§¤í•‘
            code_mapping = {
                "VO": {"label": "ì–´íœ˜ (Vocabulary)", "value": "ì–´íœ˜ ë¬¸ì œ ë‚´ì¤˜"},
                "RD": {"label": "ë…í•´ (Reading)", "value": "ë…í•´ ë¬¸ì œ ë‚´ì¤˜"},
                "WR": {"label": "ì“°ê¸° (Writing)", "value": "ì“°ê¸° ë¬¸ì œ ë‚´ì¤˜"},
                "LS": {"label": "ë“£ê¸° (Listening)", "value": "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"},
                "GR": {"label": "ë¬¸ë²• (Grammar)", "value": "ë¬¸ë²• ë¬¸ì œ ë‚´ì¤˜"}
            }

            # Quick replies ìƒì„±
            quick_replies = []
            for code in codes:
                code = code.strip()
                if code in code_mapping:
                    quick_replies.append(code_mapping[code])

            # íŒ¨í„´ ì œê±°í•œ ë©”ì‹œì§€
            clean_message = re.sub(pattern, '', content).strip()

            return {
                "message": clean_message,
                "quick_replies": quick_replies,
                "model_info": {
                    "primary": "gpt-4.1-mini",
                    "all_used": used_models
                }
            }
        else:
            # Quick reply ì—†ìœ¼ë©´ ì¼ë°˜ ì‘ë‹µ
            return {
                "message": content,
                "model_info": {
                    "primary": "gpt-4.1-mini",
                    "all_used": used_models
                }
            }

    def _execute_function(self, function_name: str, arguments: Dict[str, Any]) -> str:
        """Function ì‹¤í–‰"""
        print(f"ğŸ”§ FUNCTION CALLED: {function_name}")
        print(f"ğŸ“‹ ARGUMENTS: {json.dumps(arguments, ensure_ascii=False)}")

        if function_name == "get_student_context":
            # ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•´ í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì „ë‹¬
            return self._get_student_context(query_text=self.current_user_message, **arguments)
        elif function_name == "recommend_problems":
            return self._recommend_problems(**arguments)
        elif function_name == "generate_problem":
            return self._generate_problem(**arguments)
        elif function_name == "evaluate_writing":
            return self._evaluate_writing(**arguments)
        else:
            return f"Unknown function: {function_name}"

    def chat(
        self,
        student_id: str,
        message: str,
        chat_history: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """
        í•™ìƒê³¼ ì±„íŒ… (Function Calling)

        Args:
            student_id: í•™ìƒ ID
            message: í•™ìƒì˜ ë©”ì‹œì§€
            chat_history: ì´ì „ ëŒ€í™” ê¸°ë¡ (ì„ íƒ)

        Returns:
            Dict with 'message' and 'model_info'
        """
        try:
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ (ë²¡í„° ê²€ìƒ‰ìš©)
            self.current_user_message = message

            # "ë¬¸ì œ ë‚´ì¤˜" íŒ¨í„´ ê°ì§€ (ìœ í˜• ë¯¸ì§€ì •)
            import re
            if re.search(r'(?:ë¬¸ì œ|problem)\s*(?:ë‚´|ì¤˜|í’€|í•´)', message, re.IGNORECASE) and \
               not re.search(r'(?:ë“£ê¸°|ë…í•´|ë¬¸ë²•|ì–´íœ˜|ì“°ê¸°|listening|reading|grammar|vocabulary|writing|VO|RD|GR|LS|WR)', message, re.IGNORECASE):
                # ìœ í˜•ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ì¼ë°˜ì ì¸ "ë¬¸ì œ ë‚´ì¤˜" ìš”ì²­
                print("ğŸ” ë¬¸ì œ ìœ í˜• ì„ íƒ ìš”ì²­ ê°ì§€")
                return {
                    "message": "ì–´ë–¤ ìœ í˜•ì˜ ë¬¸ì œë¥¼ ë‚´ë“œë¦´ê¹Œìš”?",
                    "quick_replies": [
                        {"label": "ğŸ’¬ ë“£ê¸° (Listening)", "value": "ë“£ê¸° ë¬¸ì œ ë‚´ì¤˜"},
                        {"label": "ğŸ“– ë…í•´ (Reading)", "value": "ë…í•´ ë¬¸ì œ ë‚´ì¤˜"},
                        {"label": "âœï¸ ì“°ê¸° (Writing)", "value": "ì“°ê¸° ë¬¸ì œ ë‚´ì¤˜"},
                        {"label": "ğŸ“ ë¬¸ë²• (Grammar)", "value": "ë¬¸ë²• ë¬¸ì œ ë‚´ì¤˜"},
                        {"label": "ğŸ“š ì–´íœ˜ (Vocabulary)", "value": "ì–´íœ˜ ë¬¸ì œ ë‚´ì¤˜"}
                    ],
                    "model_info": {
                        "primary": "gpt-4.1-mini",
                        "all_used": ["gpt-4.1-mini"]
                    }
                }

            used_models = []  # Track models used
            # PromptManagerë¥¼ ì‚¬ìš©í•´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = PromptManager.get_system_prompt(
                role="student_agent",
                model="gpt-4.1-mini",
                context={"student_id": student_id}
            )

            # ë©”ì‹œì§€ êµ¬ì„± (ë©€í‹°í„´ ì§€ì›)
            messages = [{"role": "system", "content": system_prompt}]

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if chat_history:
                messages.extend(chat_history)

            # ìµœì‹  ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": message})

            # gpt-4.1-minië¡œ function calling (ë¹ ë¥¸ ì¸í…”ë¦¬ì „ìŠ¤ ëª¨ë¸)
            used_models.append("gpt-4.1-mini")
            response = self.client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=messages,
                tools=self.functions,
                tool_choice="auto",  # ìë™ìœ¼ë¡œ ë„êµ¬ ì„ íƒ
                temperature=0.7
            )

            assistant_message = response.choices[0].message

            # Function í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°
            if assistant_message.tool_calls:
                # Function ì‹¤í–‰
                messages.append(assistant_message)

                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)

                    print(f"ğŸ”§ Function Call: {function_name}({arguments})")

                    # Track special models used in functions
                    if function_name == "generate_problem":
                        used_models.append("o4-mini")
                    elif function_name == "evaluate_writing":
                        used_models.append("o4-mini")

                    # Function ì‹¤í–‰
                    function_response = self._execute_function(function_name, arguments)

                    # ë“£ê¸° ë¬¸ì œì˜ ê²½ìš°: [AUDIO]ì™€ [SPEAKERS] íƒœê·¸ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ì§ì ‘ ë°˜í™˜
                    if function_name == "generate_problem" and arguments.get("area", "").lower() in ['ë“£ê¸°', 'listening', 'ls']:
                        # Check if response contains [AUDIO] or [SPEAKERS]
                        if '[AUDIO]' in function_response or '[SPEAKERS]' in function_response:
                            print("ğŸ§ ë“£ê¸° ë¬¸ì œ: [AUDIO]/[SPEAKERS] íƒœê·¸ ë³´ì¡´ì„ ìœ„í•´ ì§ì ‘ ë°˜í™˜")
                            return {
                                "message": function_response,
                                "model_info": {
                                    "primary": "o4-mini",
                                    "all_used": list(set(used_models))
                                }
                            }

                    # Function ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": function_response
                    })

                # Function ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„± (DB ì¡°íšŒ ì •ì œ)
                final_response = self.client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=messages,
                    temperature=0.7
                )

                response_content = final_response.choices[0].message.content
                return self._parse_quick_reply(response_content, list(set(used_models)))
            else:
                # Function í˜¸ì¶œ ì—†ì´ ì§ì ‘ ì‘ë‹µ
                return self._parse_quick_reply(assistant_message.content, ["gpt-4.1-mini"])

        except Exception as e:
            return {
                "message": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "model_info": {"primary": "error", "all_used": []}
            }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_student_agent_service = None


def get_student_agent_service() -> StudentAgentService:
    """Student Agent ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _student_agent_service
    if _student_agent_service is None:
        _student_agent_service = StudentAgentService()
    return _student_agent_service
